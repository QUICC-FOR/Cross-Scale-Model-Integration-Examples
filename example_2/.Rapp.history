paste(mod, " + ", bname, " * ", vname, sep="")			parnames <- c(parnames, bname)		}	}	return(list(parameters=parnames, model=mod))}prior <- function(pars) {	pr <- c()	for(p in pars) {		pstr <- paste(p, "~dnorm(0,0.001)", sep="")		pr <- c(pr, pstr)	}	return(paste(pr, collapse="\n"))}#
a <- VarList("adam")vl <- c('adam','bob','carol','doug')a <- select_pars(a, vl)a <- select_pars(a, vl)a <- select_pars(a, vl)a <- select_pars(a, vl)aa <- linear_predictor(a)ap <- prior(aa$parameters)cat(ap)
rm (list=ls)
rm (list=ls())
select_vars <- function(oldVarList, varList, maxDepth=3) {	# oldVarList: a VarList object 	missingVars <- varList[!(varList %in% oldVarList$varNames)]	if(length(missingVars) > 0) {		newVarList <- rbind(oldVarList, VarList(missingVars[1], 1))	} else {		minPars <- which((oldVarList$depth < maxDepth) & (oldVarList$depth == min(oldVarList$depth)))		if(length(minPars) == 0) {			newVarList <- NA		} else {			newVarList <- oldVarList			newVarList$depth[minPars[1]] = newVarList$depth[minPars[1]] + 1		}	}	return(newVarList)}VarList <- function(vars, depthList = 1) {	pl <- data.frame(varNames=vars, depth=depthList, stringsAsFactors=FALSE)	class(pl) <- c("VarList", "data.frame")	return(pl)}linear_predictor <- function(vars) {	mod <- ("pr[i] <- b0")	parnames <- "b0"	for(i in 1:nrow(vars)) {		for(j in 1:vars$depth[i]) {			bname <- paste("b_", vars$varNames[i], j, sep="")			vname <- paste(vars$varNames[i], "[i]", sep="")			if(j > 1) vname <- paste("I(", vname, "^", j, ")", sep="") 			mod <-
paste(mod, " + ", bname, " * ", vname, sep="")			parnames <- c(parnames, bname)		}	}	return(list(parameters=parnames, model=mod))}prior <- function(pars) {	pr <- c()	for(p in pars) {		pstr <- paste(p, "~dnorm(0,0.001)", sep="")		pr <- c(pr, pstr)	}	return(paste(pr, collapse="\n"))}#
a <- VarList("adam")vl <- c('adam','bob','carol','doug')a <- select_vars(a, vl)a <- select_vars(a, vl)a <- select_vars(a, vl)a <- select_vars(a, vl)aa <- linear_predictor(a)ap <- prior(aa$parameters)cat(ap)
df1 <- data.frame(a=rnorm(5), b=runif(5))
df1
b <- a[sample(nrow(a))]
b <- a[sample(nrow(a)),]
a
df2 <- df1[sample(nrow(df1)),]
df1
df2
identical(df1, df2)
all.equal(df1, df2)
all.equal(df1[order(df1[[1]]),], df2[order(df2[[1]]),])
identical(df1[order(df1[[1]]),], df2[order(df2[[1]]),])
?get
library(jags)
library(rjags)
?gelman.diag
?dic.samples
?require
?step
?dic.samples
a <- c(1,2,3,4,5)
b <- 7:19
cc <- list(a,b)
cc
d <- cc[[2]]
d
d[3] <- 22
d
cc
?diffdic
dd <- cc
cc==dd
d
which(d > 100)
length(which(d>100))
cat("data {\n    N <- length(presence)\n}\nmodel {\n\nfor (i in 1:N) {\n    presence[i] ~ dbin(pr[i], 1)\n    logit(pr[i]) <- b0 + b1 * temp[i] + b2 * temp[i]^2 + b3 * precip[i] + b4 * precip[i]^2\n}\n\n# priors\nb0 ~ dnorm(bPrior[1,1], bPrior[1,2])\nb1 ~ dnorm(bPrior[2,1], bPrior[2,2])\nb2 ~ dnorm(bPrior[3,1], bPrior[3,2])\nb3 ~ dnorm(bPrior[4,1], bPrior[4,2])\nb4 ~ dnorm(bPrior[5,1], bPrior[5,2])\n}", file=metamodel.jags)
cat("data {\n    N <- length(presence)\n}\nmodel {\n\nfor (i in 1:N) {\n    presence[i] ~ dbin(pr[i], 1)\n    logit(pr[i]) <- b0 + b1 * temp[i] + b2 * temp[i]^2 + b3 * precip[i] + b4 * precip[i]^2\n}\n\n# priors\nb0 ~ dnorm(bPrior[1,1], bPrior[1,2])\nb1 ~ dnorm(bPrior[2,1], bPrior[2,2])\nb2 ~ dnorm(bPrior[3,1], bPrior[3,2])\nb3 ~ dnorm(bPrior[4,1], bPrior[4,2])\nb4 ~ dnorm(bPrior[5,1], bPrior[5,2])\n}", file="metamodel.jags")
cat("data {    N <- length(presence)}model {for (i in 1:N) {    presence[i] ~ dbin(pr[i], 1)    logit(pr[i]) <- b0 + b1 * temp[i] + b2 * temp[i]^2 + b3 * precip[i] + b4 * precip[i]^2}# priorsb0 ~ dnorm(bPrior[1,1], bPrior[1,2])b1 ~ dnorm(bPrior[2,1], bPrior[2,2])b2 ~ dnorm(bPrior[3,1], bPrior[3,2])b3 ~ dnorm(bPrior[4,1], bPrior[4,2])b4 ~ dnorm(bPrior[5,1], bPrior[5,2])}", file="metamodel.jags")
cat("data {	N <- length(psi)}model {for (i in 1:N) {	psi[i] ~ dbeta(p[i], q[i])	p[i] <- mu[i] * phi	q[i] <- (1-mu[i]) * phi#
	logit(mu[i]) <- a0 + a1*precip[i] + a2 * precip[i]^2}# priorsa0 ~ dnorm(0, 0.001)a1 ~ dnorm(0, 0.001)a2 ~ dnorm(0, 0.001)## uninformative prior for phi from Gelman 2006phi <- U^2U ~ dunif(0,50)}", file="ex1_model2.jags")
x=1:10#
y=jitter(10*x)#
w=sample(x,10)#
#
augmented.x=NULL#
augmented.y=NULL    #
for(i in 1:length(x)){#
    augmented.x=c(augmented.x, rep(x[i],w[i]))#
    augmented.y=c(augmented.y, rep(y[i],w[i]))#
}#
#
# These are both basically the same thing#
m.1=lm(y~x, weights=w)#
m.2=lm(augmented.y~augmented.x)
summary(m.1)
summary(m.2)
?glm
?I
Z <- scan()
S <- scan()
D <- scan()
M <- scan()
plot(D,M,type='l', col='yellow')
plot(D,M,type='l', col='green')
lines(D,Z,col='black')
lines(D,S,col='red')
plot(D,M,type='l', col='green', ylim=c(40,160))
lines(D,Z,col='black')
lines(D,S,col='red')
plot(D,M/max(M),type='l', col='green')
lines(D,Z/max(Z),col='black')
lines(D,S/max(S),col='red')
plot(D,M/max(M),type='l', col='green', ylim=c(0.8,1))
plot(D,M/max(M),type='l', col='green', ylim=c(0.85,1))
lines(D,Z/max(Z),col='black')
lines(D,S/max(S),col='red')
abline(h=48/max(S), lty=2, col='red')
abline(h=50/max(Z), lty=2, col='black')
dbinom(2,2,.1)
dbinom(2,2,.4)
dbinom(4,4,.4)
dbinom(4,4,.1)
dbinom(5,5,.4)
load('~/Desktop/int_500k.rdata')
ls
ls()
library(coda)
str(integratedModel)
plot(integratedModel$posteriorSamples)
nrow(integratedModel$posteriorSamples)
summary(integratedModel$posteriorSamples)
sample(1:42,1)
sample(1:6,1)
sample(c('action', 'com', 'drama','romance', 'horror','scifi', 'thrill'),1)
runif(10,1,100)
as.integer(runif(10,1,100))
library(ReadImages)
install.packages('ReadImages')
time = seq(-2,11,1)
hugs = c(40, 40, 37, 35, 30, 32, 28, 27, 25, 24, 22, 19, 17, 16)
plot(time, hugs, type='l')
h2 = hugs + rnorm(14,0,3)
plot(time, h2, type='l', ylim=c(0,max(h2)))
h2 = hugs + rnorm(14,0,5)
plot(time, h2, type='l', ylim=c(0,max(h2)))
plot(time, h2, type='l', ylim=c(0,max(h2)), xlab='Time since birth giver left (days)', ylab = "Hugs per day")
install.packages('pROC')
setwd("~/Documents/git_projects/Cross-Scale-Model-Integration-Examples/example_2")
# 5-make_figure.r# #   Copyright 2014 Matthew V Talluto, Isabelle Boulangeat, Dominique Gravel# #   This program is free software; you can redistribute it and/or modify#   it under the terms of the GNU General Public License as published by#   the Free Software Foundation; either version 3 of the License, or (at#   your option) any later version.#   #   This program is distributed in the hope that it will be useful, but#   WITHOUT ANY WARRANTY; without even the implied warranty of#   MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU#   General Public License for more details.# #   You should have received a copy of the GNU General Public License#   along with this program; if not, write to the Free Software#   Foundation, Inc., 51 Franklin Street, Fifth Floor, Boston, MA 02110-1301, USA.##### produce the figure for the second example###
main = function(){	require(fields)	require(rgdal)	require(coda)#
	load("dat/naive_model.rdata")	intPredictions = read.csv("results/integratedStats.csv")	load("results/integratedModel.rdata")#
	predictions = process_predictions(maple, naiveModel, intPredictions, integratedModel)	ocean = readOGR(dsn="dat/ne_110m_ocean", layer="ne_110m_ocean")	pdfFileName = "ex2.pdf"	pdfWidth = 7.5	pdfHeight = 6	titleCEX = 0.7#
	# which columns to loop thru for mean and errors	meanCols = c(3,5,7,11)	SECols = meanCols + 1	## pick the data to display	latLimits = c(27,65)	longLimits = c(-105, -55)	predictionsSub = subset(predictions$all, in.range(lat, latLimits) & in.range(long, longLimits))	mapleAllSub = subset(maple$all, in.range(lat, latLimits) & in.range(long, longLimits))	latitude = predictionsSub[,2]	longitude = predictionsSub[,1]	meanPredictions = cbind(mapleAllSub$Phenofit_CRU, mapleAllSub$Phenofit_HadA2, predictionsSub[,meanCols])	errorPredictions = predictionsSub[,SECols]	## plotting settings	meanZlims = c(0,1)	meanColors = colorRampPalette(c("#ffffff", "#bdc9e1", "#045a8d", "#33338d", "#cc99ff"), interpolate='spline', bias=1, space="rgb")(200)	meanTitles = c("A. Phenofit: Present", "B. Phenofit: HadA2", "C. Naive SDM: Present",  "D. Naive SDM: HadA2", "G. Integrated: Present", "H. Integrated: HadA2")	errorTitles = c("E. SDM: Present SE",  "F. SDM: HadA2 SE", "I. Integrated: Present SE", "J. Integrated: HadA2 SE")	meanScaleTitle = "Suitability"	errorZlims = range(errorPredictions)	errorColors = colorRampPalette(c("#ffffff", "#ffffb2", "#fecc5c", "#fd8d3c", "#e31a1c"), interpolate='spline', space="rgb", bias=1.3)(200)	errorScaleTitle = "Posterior Standard Error"	# produce the plot#	pdf(file=pdfFileName, width=pdfWidth,height=pdfHeight)	quartz(width=pdfWidth,height=pdfHeight)	plotLayout = matrix(c(		1,2,11,11,		1,2,12,12,		3,4,7,8,		5,6,9,10),	  byrow=T, nrow=4)	layout(plotLayout, heights=c(0.5, 0.5, 1, 1))	par(mar=c(1,1,1,1))	for(i in 1:ncol(meanPredictions)) {		quilt.plot(longitude, latitude, meanPredictions[,i], col=meanColors, zlim=meanZlims, add.legend=F, xaxt='n', yaxt='n', useRaster=T)		plot(ocean, col="white", add=T)		contour(longitude, latitude, meanPredictions[,3], col='red', levels=c(0.2,0.5,0.7,0.9), add=TRUE)		mtext(meanTitles[i], adj=0, cex = titleCEX)	}	for(i in 1:ncol(errorPredictions)) {		quilt.plot(longitude, latitude, errorPredictions[,i], col=errorColors, zlim=errorZlims, add.legend=F, xaxt='n', yaxt='n', useRaster=T)		plot(ocean, col="white", add=T)		mtext(errorTitles[i], adj=0, cex = titleCEX)	}	## scale bars	par(mar=c(3,1,3,1))	image(x=seq(meanZlims[1],meanZlims[2],length.out=101), z=matrix(seq(meanZlims[1], meanZlims[2],length.out=100), 		nrow=100, ncol=1), zlim=meanZlims, col=meanColors, yaxt='n', xlab='', ylab='', useRaster=T)	mtext(meanScaleTitle, line=0.5, cex = titleCEX)	image(x=seq(errorZlims[1],errorZlims[2],length.out=101), z=matrix(seq(errorZlims[1], errorZlims[2],length.out=100), 		nrow=100, ncol=1), zlim=errorZlims, col=errorColors, yaxt='n', xlab='', ylab='', useRaster=T)	mtext(errorScaleTitle, line=0.5, cex = titleCEX)#	dev.off()}#
process_predictions = function(maple, naiveModel, intPredictions, intPosterior){##	builds an object containing the predictions of all models, both for all of the#	original data points (in result$all) and for the validation points (result$valid)##	maple: the same maple object saved in step 1#	naiveModel: the glm object representing the naive model#	intPredictions: a data frame of predictions (produced in step 4)#	intPosterior: the posterior samples from the integrated model, produced by step 3#	require(pROC)	# extract only the relevant climate variables	presClimate = maple$all[,which(colnames(maple$calib) %in% 		unique(naiveModel$variables$varNames))]	futClimate = maple$all[,which(substr(colnames(maple$calib),5, nchar(colnames(maple$calib)))		%in% unique(naiveModel$variables$varNames))]	validationClimate = maple$valid[,which(colnames(maple$calib) %in% 		unique(naiveModel$variables$varNames))]	colnames(futClimate) = colnames(presClimate)	# apply the transformations used in the calibration data to the projection datasets	presClimate = as.data.frame(sapply(names(presClimate), function(name) {		maple$transformations[[name]]$forward(presClimate[,name])}))	futClimate = as.data.frame(sapply(names(futClimate), function(name) {		maple$transformations[[name]]$forward(futClimate[,name])}))	validationClimate = as.data.frame(sapply(names(validationClimate), function(name) {		maple$transformations[[name]]$forward(validationClimate[,name])}))	# produce predictions for the naive model	naivePresPred = predict(naiveModel$model, newdata=presClimate, type='response', se.fit=TRUE)	naiveFutPred = predict(naiveModel$model, newdata=futClimate, type='response', se.fit=TRUE)	naiveValidPred = predict(naiveModel$model, newdata=validationClimate, type='response', se.fit=FALSE)	# wrap everything into a data frame	predictions = cbind(maple$all[,1:2], naivePresPred$fit, naivePresPred$se.fit, 		naiveFutPred$fit, naiveFutPred$se.fit, intPredictions)	colnames(predictions) = c("long", "lat", 		'naivePresent', 'naivePresentSE', 'naiveFuture', 'naiveFutureSE',		'intPresent', 'intPresentSE', 'intPresentLower', 'intPresentUpper',		'intFuture', 'intFutureSE', 'intFutureLower', 'intFutureUpper')	# validation	intValidPred = predict_mcmc(intPosterior, validationClimate)	validation = list(data = cbind(maple$valid[,1:5], naiveValidPred, intValidPred))	colnames(validation$data) = c('long', 'lat', 'presence', 'phenofitPres', 'phenofitFut', 'naive', 'integrated')	validation$naiveROC = roc(validation$data$presence, validation$data$naive)	validation$phenofitROC = roc(validation$data$presence, validation$data$phenofitPres)	validation$integratedROC = roc(validation$data$presence, validation$data$integrated)#
	return(list(all=predictions, valid=validation))}#
predict_mcmc = function(posteriorSample, newData) {##	Works like predict(), but for mcmc samples#	Returns the average prediction for each point in the new dataset#	#	posteriorSample: mcmc object; the posterior sample from which to produce predictions#	newData: data frame of predictors where predictions should be produced#	parPrefix = 2	parEnd = 1	#
	# predict the prob of presence for each point in newData	# assumes the FIRST parameter in posteriorSample is the intercept	predictedPrPresenceMean = mean(posteriorSample[,1])	currentCol = 2	while(currentCol <= ncol(posteriorSample)) {		ndColumn = which(colnames(newData) == substr(colnames(posteriorSample)[currentCol], parPrefix + 1, nchar(colnames(posteriorSample)[currentCol]) - parEnd))		exponent = as.integer(substr(colnames(posteriorSample)[currentCol], nchar(colnames(posteriorSample)[currentCol]), nchar(colnames(posteriorSample)[currentCol])))		predictedPrPresenceMean = predictedPrPresenceMean + mean(posteriorSample[,currentCol]) * newData[,ndColumn]^exponent				currentCol = currentCol + 1	}	predictedPrPresenceMean = inv_logit(predictedPrPresenceMean)		return(predictedPrPresenceMean)}#
inv_logit = function(x) {	inf.ind = which(x == Inf)		# negative infinity works normally, but Inf returns NaN	result = exp(x) / (1+exp(x))	result[inf.ind] = 1	return(result)}in.range = function(x, lims) x >= lims[1] & x <= lims[2]#
main()
load("dat/naive_model.rdata")	intPredictions = read.csv("results/integratedStats.csv")	load("results/integratedModel.rdata")#
	predictions = process_predictions(maple, naiveModel, intPredictions, integratedModel)	ocean = readOGR(dsn="dat/ne_110m_ocean", layer="ne_110m_ocean")	pdfFileName = "ex2.pdf"	pdfWidth = 7.5	pdfHeight = 6	titleCEX = 0.7#
	# which columns to loop thru for mean and errors	meanCols = c(3,5,7,11)	SECols = meanCols + 1	## pick the data to display	latLimits = c(27,65)	longLimits = c(-105, -55)	predictionsSub = subset(predictions$all, in.range(lat, latLimits) & in.range(long, longLimits))	mapleAllSub = subset(maple$all, in.range(lat, latLimits) & in.range(long, longLimits))	latitude = predictionsSub[,2]	longitude = predictionsSub[,1]	meanPredictions = cbind(mapleAllSub$Phenofit_CRU, mapleAllSub$Phenofit_HadA2, predictionsSub[,meanCols])	errorPredictions = predictionsSub[,SECols]	## plotting settings	meanZlims = c(0,1)	meanColors = colorRampPalette(c("#ffffff", "#bdc9e1", "#045a8d", "#33338d", "#cc99ff"), interpolate='spline', bias=1, space="rgb")(200)	meanTitles = c("A. Phenofit: Present", "B. Phenofit: HadA2", "C. Naive SDM: Present",  "D. Naive SDM: HadA2", "G. Integrated: Present", "H. Integrated: HadA2")	errorTitles = c("E. SDM: Present SE",  "F. SDM: HadA2 SE", "I. Integrated: Present SE", "J. Integrated: HadA2 SE")	meanScaleTitle = "Suitability"	errorZlims = range(errorPredictions)	errorColors = colorRampPalette(c("#ffffff", "#ffffb2", "#fecc5c", "#fd8d3c", "#e31a1c"), interpolate='spline', space="rgb", bias=1.3)(200)	errorScaleTitle = "Posterior Standard Error"
longitude
require(reshape2)	tmp = data.frame(x = longitude, y = latitude, z = meanPredictions[,3])	tmp = tmp[order(tmp$x, tmp$y),]	contourDat = list(x = unique(tmp$x), y = unique(tmp$y), z = acast(tmp, x~y, value.var='z'))
contour(contourDat$x, contourDat$y, contourDat$z)
# 5-make_figure.r# #   Copyright 2014 Matthew V Talluto, Isabelle Boulangeat, Dominique Gravel# #   This program is free software; you can redistribute it and/or modify#   it under the terms of the GNU General Public License as published by#   the Free Software Foundation; either version 3 of the License, or (at#   your option) any later version.#   #   This program is distributed in the hope that it will be useful, but#   WITHOUT ANY WARRANTY; without even the implied warranty of#   MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU#   General Public License for more details.# #   You should have received a copy of the GNU General Public License#   along with this program; if not, write to the Free Software#   Foundation, Inc., 51 Franklin Street, Fifth Floor, Boston, MA 02110-1301, USA.##### produce the figure for the second example###
main = function(){	require(fields)	require(rgdal)	require(coda)#
	load("dat/naive_model.rdata")	intPredictions = read.csv("results/integratedStats.csv")	load("results/integratedModel.rdata")#
	predictions = process_predictions(maple, naiveModel, intPredictions, integratedModel)	ocean = readOGR(dsn="dat/ne_110m_ocean", layer="ne_110m_ocean")	pdfFileName = "ex2.pdf"	pdfWidth = 7.5	pdfHeight = 6	titleCEX = 0.7#
	# which columns to loop thru for mean and errors	meanCols = c(3,5,7,11)	SECols = meanCols + 1	## pick the data to display	latLimits = c(27,65)	longLimits = c(-105, -55)	predictionsSub = subset(predictions$all, in.range(lat, latLimits) & in.range(long, longLimits))	mapleAllSub = subset(maple$all, in.range(lat, latLimits) & in.range(long, longLimits))	latitude = predictionsSub[,2]	longitude = predictionsSub[,1]	meanPredictions = cbind(mapleAllSub$Phenofit_CRU, mapleAllSub$Phenofit_HadA2, predictionsSub[,meanCols])	errorPredictions = predictionsSub[,SECols]	## plotting settings	meanZlims = c(0,1)	meanColors = colorRampPalette(c("#ffffff", "#bdc9e1", "#045a8d", "#33338d", "#cc99ff"), interpolate='spline', bias=1, space="rgb")(200)	meanTitles = c("A. Phenofit: Present", "B. Phenofit: HadA2", "C. Naive SDM: Present",  "D. Naive SDM: HadA2", "G. Integrated: Present", "H. Integrated: HadA2")	errorTitles = c("E. SDM: Present SE",  "F. SDM: HadA2 SE", "I. Integrated: Present SE", "J. Integrated: HadA2 SE")	meanScaleTitle = "Suitability"	errorZlims = range(errorPredictions)	errorColors = colorRampPalette(c("#ffffff", "#ffffb2", "#fecc5c", "#fd8d3c", "#e31a1c"), interpolate='spline', space="rgb", bias=1.3)(200)	errorScaleTitle = "Posterior Standard Error"	# prepare data for contour plot	require(reshape2)	tmp = data.frame(x = longitude, y = latitude, z = meanPredictions[,3])	tmp = tmp[order(tmp$x, tmp$y),]	contourDat = list(x = unique(tmp$x), y = unique(tmp$y), z = acast(tmp, x~y, value.var='z'))	rm(tmp)#
	# produce the plot#	pdf(file=pdfFileName, width=pdfWidth,height=pdfHeight)	quartz(width=pdfWidth,height=pdfHeight)	plotLayout = matrix(c(		1,2,11,11,		1,2,12,12,		3,4,7,8,		5,6,9,10),	  byrow=T, nrow=4)	layout(plotLayout, heights=c(0.5, 0.5, 1, 1))	par(mar=c(1,1,1,1))	for(i in 1:ncol(meanPredictions)) {		quilt.plot(longitude, latitude, meanPredictions[,i], col=meanColors, zlim=meanZlims, add.legend=F, xaxt='n', yaxt='n', useRaster=T)		plot(ocean, col="white", add=T)		contour(contourDat$x, contourDat$y, contourDat$z, col='red', levels=c(0.2,0.5,0.7,0.9), add=TRUE)		mtext(meanTitles[i], adj=0, cex = titleCEX)	}	for(i in 1:ncol(errorPredictions)) {		quilt.plot(longitude, latitude, errorPredictions[,i], col=errorColors, zlim=errorZlims, add.legend=F, xaxt='n', yaxt='n', useRaster=T)		plot(ocean, col="white", add=T)		mtext(errorTitles[i], adj=0, cex = titleCEX)	}	## scale bars	par(mar=c(3,1,3,1))	image(x=seq(meanZlims[1],meanZlims[2],length.out=101), z=matrix(seq(meanZlims[1], meanZlims[2],length.out=100), 		nrow=100, ncol=1), zlim=meanZlims, col=meanColors, yaxt='n', xlab='', ylab='', useRaster=T)	mtext(meanScaleTitle, line=0.5, cex = titleCEX)	image(x=seq(errorZlims[1],errorZlims[2],length.out=101), z=matrix(seq(errorZlims[1], errorZlims[2],length.out=100), 		nrow=100, ncol=1), zlim=errorZlims, col=errorColors, yaxt='n', xlab='', ylab='', useRaster=T)	mtext(errorScaleTitle, line=0.5, cex = titleCEX)#	dev.off()}#
process_predictions = function(maple, naiveModel, intPredictions, intPosterior){##	builds an object containing the predictions of all models, both for all of the#	original data points (in result$all) and for the validation points (result$valid)##	maple: the same maple object saved in step 1#	naiveModel: the glm object representing the naive model#	intPredictions: a data frame of predictions (produced in step 4)#	intPosterior: the posterior samples from the integrated model, produced by step 3#	require(pROC)	# extract only the relevant climate variables	presClimate = maple$all[,which(colnames(maple$calib) %in% 		unique(naiveModel$variables$varNames))]	futClimate = maple$all[,which(substr(colnames(maple$calib),5, nchar(colnames(maple$calib)))		%in% unique(naiveModel$variables$varNames))]	validationClimate = maple$valid[,which(colnames(maple$calib) %in% 		unique(naiveModel$variables$varNames))]	colnames(futClimate) = colnames(presClimate)	# apply the transformations used in the calibration data to the projection datasets	presClimate = as.data.frame(sapply(names(presClimate), function(name) {		maple$transformations[[name]]$forward(presClimate[,name])}))	futClimate = as.data.frame(sapply(names(futClimate), function(name) {		maple$transformations[[name]]$forward(futClimate[,name])}))	validationClimate = as.data.frame(sapply(names(validationClimate), function(name) {		maple$transformations[[name]]$forward(validationClimate[,name])}))	# produce predictions for the naive model	naivePresPred = predict(naiveModel$model, newdata=presClimate, type='response', se.fit=TRUE)	naiveFutPred = predict(naiveModel$model, newdata=futClimate, type='response', se.fit=TRUE)	naiveValidPred = predict(naiveModel$model, newdata=validationClimate, type='response', se.fit=FALSE)	# wrap everything into a data frame	predictions = cbind(maple$all[,1:2], naivePresPred$fit, naivePresPred$se.fit, 		naiveFutPred$fit, naiveFutPred$se.fit, intPredictions)	colnames(predictions) = c("long", "lat", 		'naivePresent', 'naivePresentSE', 'naiveFuture', 'naiveFutureSE',		'intPresent', 'intPresentSE', 'intPresentLower', 'intPresentUpper',		'intFuture', 'intFutureSE', 'intFutureLower', 'intFutureUpper')	# validation	intValidPred = predict_mcmc(intPosterior, validationClimate)	validation = list(data = cbind(maple$valid[,1:5], naiveValidPred, intValidPred))	colnames(validation$data) = c('long', 'lat', 'presence', 'phenofitPres', 'phenofitFut', 'naive', 'integrated')	validation$naiveROC = roc(validation$data$presence, validation$data$naive)	validation$phenofitROC = roc(validation$data$presence, validation$data$phenofitPres)	validation$integratedROC = roc(validation$data$presence, validation$data$integrated)#
	return(list(all=predictions, valid=validation))}#
predict_mcmc = function(posteriorSample, newData) {##	Works like predict(), but for mcmc samples#	Returns the average prediction for each point in the new dataset#	#	posteriorSample: mcmc object; the posterior sample from which to produce predictions#	newData: data frame of predictors where predictions should be produced#	parPrefix = 2	parEnd = 1	#
	# predict the prob of presence for each point in newData	# assumes the FIRST parameter in posteriorSample is the intercept	predictedPrPresenceMean = mean(posteriorSample[,1])	currentCol = 2	while(currentCol <= ncol(posteriorSample)) {		ndColumn = which(colnames(newData) == substr(colnames(posteriorSample)[currentCol], parPrefix + 1, nchar(colnames(posteriorSample)[currentCol]) - parEnd))		exponent = as.integer(substr(colnames(posteriorSample)[currentCol], nchar(colnames(posteriorSample)[currentCol]), nchar(colnames(posteriorSample)[currentCol])))		predictedPrPresenceMean = predictedPrPresenceMean + mean(posteriorSample[,currentCol]) * newData[,ndColumn]^exponent				currentCol = currentCol + 1	}	predictedPrPresenceMean = inv_logit(predictedPrPresenceMean)		return(predictedPrPresenceMean)}#
inv_logit = function(x) {	inf.ind = which(x == Inf)		# negative infinity works normally, but Inf returns NaN	result = exp(x) / (1+exp(x))	result[inf.ind] = 1	return(result)}in.range = function(x, lims) x >= lims[1] & x <= lims[2]#
main()
# 5-make_figure.r# #   Copyright 2014 Matthew V Talluto, Isabelle Boulangeat, Dominique Gravel# #   This program is free software; you can redistribute it and/or modify#   it under the terms of the GNU General Public License as published by#   the Free Software Foundation; either version 3 of the License, or (at#   your option) any later version.#   #   This program is distributed in the hope that it will be useful, but#   WITHOUT ANY WARRANTY; without even the implied warranty of#   MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU#   General Public License for more details.# #   You should have received a copy of the GNU General Public License#   along with this program; if not, write to the Free Software#   Foundation, Inc., 51 Franklin Street, Fifth Floor, Boston, MA 02110-1301, USA.##### produce the figure for the second example###
main = function(){	require(fields)	require(rgdal)	require(coda)#
	load("dat/naive_model.rdata")	intPredictions = read.csv("results/integratedStats.csv")	load("results/integratedModel.rdata")#
	predictions = process_predictions(maple, naiveModel, intPredictions, integratedModel)	ocean = readOGR(dsn="dat/ne_110m_ocean", layer="ne_110m_ocean")	pdfFileName = "ex2.pdf"	pdfWidth = 7.5	pdfHeight = 6	titleCEX = 0.7#
	# which columns to loop thru for mean and errors	meanCols = c(3,5,7,11)	SECols = meanCols + 1	## pick the data to display	latLimits = c(27,65)	longLimits = c(-105, -55)	predictionsSub = subset(predictions$all, in.range(lat, latLimits) & in.range(long, longLimits))	mapleAllSub = subset(maple$all, in.range(lat, latLimits) & in.range(long, longLimits))	latitude = predictionsSub[,2]	longitude = predictionsSub[,1]	meanPredictions = cbind(mapleAllSub$Phenofit_CRU, mapleAllSub$Phenofit_HadA2, predictionsSub[,meanCols])	errorPredictions = predictionsSub[,SECols]	## plotting settings	meanZlims = c(0,1)	meanColors = colorRampPalette(c("#ffffff", "#bdc9e1", "#045a8d", "#33338d", "#cc99ff"), interpolate='spline', bias=1, space="rgb")(200)	meanTitles = c("A. Phenofit: Present", "B. Phenofit: HadA2", "C. Naive SDM: Present",  "D. Naive SDM: HadA2", "G. Integrated: Present", "H. Integrated: HadA2")	errorTitles = c("E. SDM: Present SE",  "F. SDM: HadA2 SE", "I. Integrated: Present SE", "J. Integrated: HadA2 SE")	meanScaleTitle = "Suitability"	errorZlims = range(errorPredictions)	errorColors = colorRampPalette(c("#ffffff", "#ffffb2", "#fecc5c", "#fd8d3c", "#e31a1c"), interpolate='spline', space="rgb", bias=1.3)(200)	errorScaleTitle = "Posterior Standard Error"	# prepare data for contour plot	require(reshape2)	tmp = data.frame(x = longitude, y = latitude, z = meanPredictions[,3])	tmp = tmp[order(tmp$x, tmp$y),]	contourDat = list(x = unique(tmp$x), y = unique(tmp$y), z = acast(tmp, x~y, value.var='z'))	rm(tmp)#
	# produce the plot#	pdf(file=pdfFileName, width=pdfWidth,height=pdfHeight)	quartz(width=pdfWidth,height=pdfHeight)	plotLayout = matrix(c(		1,2,11,11,		1,2,12,12,		3,4,7,8,		5,6,9,10),	  byrow=T, nrow=4)	layout(plotLayout, heights=c(0.5, 0.5, 1, 1))	par(mar=c(1,1,1,1))	for(i in 1:ncol(meanPredictions)) {		quilt.plot(longitude, latitude, meanPredictions[,i], col=meanColors, zlim=meanZlims, add.legend=F, xaxt='n', yaxt='n', useRaster=T)		plot(ocean, col="white", add=T)		contour(contourDat$x, contourDat$y, contourDat$z, col='red', levels=c(0.3, 0.4), add=TRUE, lwd=1.5)		mtext(meanTitles[i], adj=0, cex = titleCEX)	}	for(i in 1:ncol(errorPredictions)) {		quilt.plot(longitude, latitude, errorPredictions[,i], col=errorColors, zlim=errorZlims, add.legend=F, xaxt='n', yaxt='n', useRaster=T)		plot(ocean, col="white", add=T)		mtext(errorTitles[i], adj=0, cex = titleCEX)	}	## scale bars	par(mar=c(3,1,3,1))	image(x=seq(meanZlims[1],meanZlims[2],length.out=101), z=matrix(seq(meanZlims[1], meanZlims[2],length.out=100), 		nrow=100, ncol=1), zlim=meanZlims, col=meanColors, yaxt='n', xlab='', ylab='', useRaster=T)	mtext(meanScaleTitle, line=0.5, cex = titleCEX)	image(x=seq(errorZlims[1],errorZlims[2],length.out=101), z=matrix(seq(errorZlims[1], errorZlims[2],length.out=100), 		nrow=100, ncol=1), zlim=errorZlims, col=errorColors, yaxt='n', xlab='', ylab='', useRaster=T)	mtext(errorScaleTitle, line=0.5, cex = titleCEX)#	dev.off()}#
process_predictions = function(maple, naiveModel, intPredictions, intPosterior){##	builds an object containing the predictions of all models, both for all of the#	original data points (in result$all) and for the validation points (result$valid)##	maple: the same maple object saved in step 1#	naiveModel: the glm object representing the naive model#	intPredictions: a data frame of predictions (produced in step 4)#	intPosterior: the posterior samples from the integrated model, produced by step 3#	require(pROC)	# extract only the relevant climate variables	presClimate = maple$all[,which(colnames(maple$calib) %in% 		unique(naiveModel$variables$varNames))]	futClimate = maple$all[,which(substr(colnames(maple$calib),5, nchar(colnames(maple$calib)))		%in% unique(naiveModel$variables$varNames))]	validationClimate = maple$valid[,which(colnames(maple$calib) %in% 		unique(naiveModel$variables$varNames))]	colnames(futClimate) = colnames(presClimate)	# apply the transformations used in the calibration data to the projection datasets	presClimate = as.data.frame(sapply(names(presClimate), function(name) {		maple$transformations[[name]]$forward(presClimate[,name])}))	futClimate = as.data.frame(sapply(names(futClimate), function(name) {		maple$transformations[[name]]$forward(futClimate[,name])}))	validationClimate = as.data.frame(sapply(names(validationClimate), function(name) {		maple$transformations[[name]]$forward(validationClimate[,name])}))	# produce predictions for the naive model	naivePresPred = predict(naiveModel$model, newdata=presClimate, type='response', se.fit=TRUE)	naiveFutPred = predict(naiveModel$model, newdata=futClimate, type='response', se.fit=TRUE)	naiveValidPred = predict(naiveModel$model, newdata=validationClimate, type='response', se.fit=FALSE)	# wrap everything into a data frame	predictions = cbind(maple$all[,1:2], naivePresPred$fit, naivePresPred$se.fit, 		naiveFutPred$fit, naiveFutPred$se.fit, intPredictions)	colnames(predictions) = c("long", "lat", 		'naivePresent', 'naivePresentSE', 'naiveFuture', 'naiveFutureSE',		'intPresent', 'intPresentSE', 'intPresentLower', 'intPresentUpper',		'intFuture', 'intFutureSE', 'intFutureLower', 'intFutureUpper')	# validation	intValidPred = predict_mcmc(intPosterior, validationClimate)	validation = list(data = cbind(maple$valid[,1:5], naiveValidPred, intValidPred))	colnames(validation$data) = c('long', 'lat', 'presence', 'phenofitPres', 'phenofitFut', 'naive', 'integrated')	validation$naiveROC = roc(validation$data$presence, validation$data$naive)	validation$phenofitROC = roc(validation$data$presence, validation$data$phenofitPres)	validation$integratedROC = roc(validation$data$presence, validation$data$integrated)#
	return(list(all=predictions, valid=validation))}#
predict_mcmc = function(posteriorSample, newData) {##	Works like predict(), but for mcmc samples#	Returns the average prediction for each point in the new dataset#	#	posteriorSample: mcmc object; the posterior sample from which to produce predictions#	newData: data frame of predictors where predictions should be produced#	parPrefix = 2	parEnd = 1	#
	# predict the prob of presence for each point in newData	# assumes the FIRST parameter in posteriorSample is the intercept	predictedPrPresenceMean = mean(posteriorSample[,1])	currentCol = 2	while(currentCol <= ncol(posteriorSample)) {		ndColumn = which(colnames(newData) == substr(colnames(posteriorSample)[currentCol], parPrefix + 1, nchar(colnames(posteriorSample)[currentCol]) - parEnd))		exponent = as.integer(substr(colnames(posteriorSample)[currentCol], nchar(colnames(posteriorSample)[currentCol]), nchar(colnames(posteriorSample)[currentCol])))		predictedPrPresenceMean = predictedPrPresenceMean + mean(posteriorSample[,currentCol]) * newData[,ndColumn]^exponent				currentCol = currentCol + 1	}	predictedPrPresenceMean = inv_logit(predictedPrPresenceMean)		return(predictedPrPresenceMean)}#
inv_logit = function(x) {	inf.ind = which(x == Inf)		# negative infinity works normally, but Inf returns NaN	result = exp(x) / (1+exp(x))	result[inf.ind] = 1	return(result)}in.range = function(x, lims) x >= lims[1] & x <= lims[2]#
main()
# 5-make_figure.r# #   Copyright 2014 Matthew V Talluto, Isabelle Boulangeat, Dominique Gravel# #   This program is free software; you can redistribute it and/or modify#   it under the terms of the GNU General Public License as published by#   the Free Software Foundation; either version 3 of the License, or (at#   your option) any later version.#   #   This program is distributed in the hope that it will be useful, but#   WITHOUT ANY WARRANTY; without even the implied warranty of#   MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU#   General Public License for more details.# #   You should have received a copy of the GNU General Public License#   along with this program; if not, write to the Free Software#   Foundation, Inc., 51 Franklin Street, Fifth Floor, Boston, MA 02110-1301, USA.##### produce the figure for the second example###
main = function(){	require(fields)	require(rgdal)	require(coda)#
	load("dat/naive_model.rdata")	intPredictions = read.csv("results/integratedStats.csv")	load("results/integratedModel.rdata")#
	predictions = process_predictions(maple, naiveModel, intPredictions, integratedModel)	ocean = readOGR(dsn="dat/ne_110m_ocean", layer="ne_110m_ocean")	pdfFileName = "ex2.pdf"	pdfWidth = 7.5	pdfHeight = 6	titleCEX = 0.7#
	# which columns to loop thru for mean and errors	meanCols = c(3,5,7,11)	SECols = meanCols + 1	## pick the data to display	latLimits = c(27,65)	longLimits = c(-105, -55)	predictionsSub = subset(predictions$all, in.range(lat, latLimits) & in.range(long, longLimits))	mapleAllSub = subset(maple$all, in.range(lat, latLimits) & in.range(long, longLimits))	latitude = predictionsSub[,2]	longitude = predictionsSub[,1]	meanPredictions = cbind(mapleAllSub$Phenofit_CRU, mapleAllSub$Phenofit_HadA2, predictionsSub[,meanCols])	errorPredictions = predictionsSub[,SECols]	## plotting settings	meanZlims = c(0,1)	meanColors = colorRampPalette(c("#ffffff", "#bdc9e1", "#045a8d", "#33338d", "#cc99ff"), interpolate='spline', bias=1, space="rgb")(200)	meanTitles = c("A. Phenofit: Present", "B. Phenofit: HadA2", "C. Naive SDM: Present",  "D. Naive SDM: HadA2", "G. Integrated: Present", "H. Integrated: HadA2")	errorTitles = c("E. SDM: Present SE",  "F. SDM: HadA2 SE", "I. Integrated: Present SE", "J. Integrated: HadA2 SE")	meanScaleTitle = "Suitability"	errorZlims = range(errorPredictions)	errorColors = colorRampPalette(c("#ffffff", "#ffffb2", "#fecc5c", "#fd8d3c", "#e31a1c"), interpolate='spline', space="rgb", bias=1.3)(200)	errorScaleTitle = "Posterior Standard Error"	# prepare data for contour plot	require(reshape2)	tmp = data.frame(x = longitude, y = latitude, z = meanPredictions[,3])	tmp = tmp[order(tmp$x, tmp$y),]	contourDat = list(x = unique(tmp$x), y = unique(tmp$y), z = acast(tmp, x~y, value.var='z'))	rm(tmp)#
	# produce the plot#	pdf(file=pdfFileName, width=pdfWidth,height=pdfHeight)	quartz(width=pdfWidth,height=pdfHeight)	plotLayout = matrix(c(		1,2,11,11,		1,2,12,12,		3,4,7,8,		5,6,9,10),	  byrow=T, nrow=4)	layout(plotLayout, heights=c(0.5, 0.5, 1, 1))	par(mar=c(1,1,1,1))	for(i in 1:ncol(meanPredictions)) {		quilt.plot(longitude, latitude, meanPredictions[,i], col=meanColors, zlim=meanZlims, add.legend=F, xaxt='n', yaxt='n', useRaster=T)		plot(ocean, col="white", add=T)		contour(contourDat$x, contourDat$y, contourDat$z, col='red', levels=c(0.3, 0.4), add=TRUE, lwd=1.5, labels='')		mtext(meanTitles[i], adj=0, cex = titleCEX)	}	for(i in 1:ncol(errorPredictions)) {		quilt.plot(longitude, latitude, errorPredictions[,i], col=errorColors, zlim=errorZlims, add.legend=F, xaxt='n', yaxt='n', useRaster=T)		plot(ocean, col="white", add=T)		mtext(errorTitles[i], adj=0, cex = titleCEX)	}	## scale bars	par(mar=c(3,1,3,1))	image(x=seq(meanZlims[1],meanZlims[2],length.out=101), z=matrix(seq(meanZlims[1], meanZlims[2],length.out=100), 		nrow=100, ncol=1), zlim=meanZlims, col=meanColors, yaxt='n', xlab='', ylab='', useRaster=T)	mtext(meanScaleTitle, line=0.5, cex = titleCEX)	image(x=seq(errorZlims[1],errorZlims[2],length.out=101), z=matrix(seq(errorZlims[1], errorZlims[2],length.out=100), 		nrow=100, ncol=1), zlim=errorZlims, col=errorColors, yaxt='n', xlab='', ylab='', useRaster=T)	mtext(errorScaleTitle, line=0.5, cex = titleCEX)#	dev.off()}#
process_predictions = function(maple, naiveModel, intPredictions, intPosterior){##	builds an object containing the predictions of all models, both for all of the#	original data points (in result$all) and for the validation points (result$valid)##	maple: the same maple object saved in step 1#	naiveModel: the glm object representing the naive model#	intPredictions: a data frame of predictions (produced in step 4)#	intPosterior: the posterior samples from the integrated model, produced by step 3#	require(pROC)	# extract only the relevant climate variables	presClimate = maple$all[,which(colnames(maple$calib) %in% 		unique(naiveModel$variables$varNames))]	futClimate = maple$all[,which(substr(colnames(maple$calib),5, nchar(colnames(maple$calib)))		%in% unique(naiveModel$variables$varNames))]	validationClimate = maple$valid[,which(colnames(maple$calib) %in% 		unique(naiveModel$variables$varNames))]	colnames(futClimate) = colnames(presClimate)	# apply the transformations used in the calibration data to the projection datasets	presClimate = as.data.frame(sapply(names(presClimate), function(name) {		maple$transformations[[name]]$forward(presClimate[,name])}))	futClimate = as.data.frame(sapply(names(futClimate), function(name) {		maple$transformations[[name]]$forward(futClimate[,name])}))	validationClimate = as.data.frame(sapply(names(validationClimate), function(name) {		maple$transformations[[name]]$forward(validationClimate[,name])}))	# produce predictions for the naive model	naivePresPred = predict(naiveModel$model, newdata=presClimate, type='response', se.fit=TRUE)	naiveFutPred = predict(naiveModel$model, newdata=futClimate, type='response', se.fit=TRUE)	naiveValidPred = predict(naiveModel$model, newdata=validationClimate, type='response', se.fit=FALSE)	# wrap everything into a data frame	predictions = cbind(maple$all[,1:2], naivePresPred$fit, naivePresPred$se.fit, 		naiveFutPred$fit, naiveFutPred$se.fit, intPredictions)	colnames(predictions) = c("long", "lat", 		'naivePresent', 'naivePresentSE', 'naiveFuture', 'naiveFutureSE',		'intPresent', 'intPresentSE', 'intPresentLower', 'intPresentUpper',		'intFuture', 'intFutureSE', 'intFutureLower', 'intFutureUpper')	# validation	intValidPred = predict_mcmc(intPosterior, validationClimate)	validation = list(data = cbind(maple$valid[,1:5], naiveValidPred, intValidPred))	colnames(validation$data) = c('long', 'lat', 'presence', 'phenofitPres', 'phenofitFut', 'naive', 'integrated')	validation$naiveROC = roc(validation$data$presence, validation$data$naive)	validation$phenofitROC = roc(validation$data$presence, validation$data$phenofitPres)	validation$integratedROC = roc(validation$data$presence, validation$data$integrated)#
	return(list(all=predictions, valid=validation))}#
predict_mcmc = function(posteriorSample, newData) {##	Works like predict(), but for mcmc samples#	Returns the average prediction for each point in the new dataset#	#	posteriorSample: mcmc object; the posterior sample from which to produce predictions#	newData: data frame of predictors where predictions should be produced#	parPrefix = 2	parEnd = 1	#
	# predict the prob of presence for each point in newData	# assumes the FIRST parameter in posteriorSample is the intercept	predictedPrPresenceMean = mean(posteriorSample[,1])	currentCol = 2	while(currentCol <= ncol(posteriorSample)) {		ndColumn = which(colnames(newData) == substr(colnames(posteriorSample)[currentCol], parPrefix + 1, nchar(colnames(posteriorSample)[currentCol]) - parEnd))		exponent = as.integer(substr(colnames(posteriorSample)[currentCol], nchar(colnames(posteriorSample)[currentCol]), nchar(colnames(posteriorSample)[currentCol])))		predictedPrPresenceMean = predictedPrPresenceMean + mean(posteriorSample[,currentCol]) * newData[,ndColumn]^exponent				currentCol = currentCol + 1	}	predictedPrPresenceMean = inv_logit(predictedPrPresenceMean)		return(predictedPrPresenceMean)}#
inv_logit = function(x) {	inf.ind = which(x == Inf)		# negative infinity works normally, but Inf returns NaN	result = exp(x) / (1+exp(x))	result[inf.ind] = 1	return(result)}in.range = function(x, lims) x >= lims[1] & x <= lims[2]#
main()
# 5-make_figure.r# #   Copyright 2014 Matthew V Talluto, Isabelle Boulangeat, Dominique Gravel# #   This program is free software; you can redistribute it and/or modify#   it under the terms of the GNU General Public License as published by#   the Free Software Foundation; either version 3 of the License, or (at#   your option) any later version.#   #   This program is distributed in the hope that it will be useful, but#   WITHOUT ANY WARRANTY; without even the implied warranty of#   MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU#   General Public License for more details.# #   You should have received a copy of the GNU General Public License#   along with this program; if not, write to the Free Software#   Foundation, Inc., 51 Franklin Street, Fifth Floor, Boston, MA 02110-1301, USA.##### produce the figure for the second example###
main = function(){	require(fields)	require(rgdal)	require(coda)#
	load("dat/naive_model.rdata")	intPredictions = read.csv("results/integratedStats.csv")	load("results/integratedModel.rdata")#
	predictions = process_predictions(maple, naiveModel, intPredictions, integratedModel)	ocean = readOGR(dsn="dat/ne_110m_ocean", layer="ne_110m_ocean")	pdfFileName = "ex2.pdf"	pdfWidth = 7.5	pdfHeight = 6	titleCEX = 0.7#
	# which columns to loop thru for mean and errors	meanCols = c(3,5,7,11)	SECols = meanCols + 1	## pick the data to display	latLimits = c(27,65)	longLimits = c(-105, -55)	predictionsSub = subset(predictions$all, in.range(lat, latLimits) & in.range(long, longLimits))	mapleAllSub = subset(maple$all, in.range(lat, latLimits) & in.range(long, longLimits))	latitude = predictionsSub[,2]	longitude = predictionsSub[,1]	meanPredictions = cbind(mapleAllSub$Phenofit_CRU, mapleAllSub$Phenofit_HadA2, predictionsSub[,meanCols])	errorPredictions = predictionsSub[,SECols]	## plotting settings	meanZlims = c(0,1)	meanColors = colorRampPalette(c("#ffffff", "#bdc9e1", "#045a8d", "#33338d", "#cc99ff"), interpolate='spline', bias=1, space="rgb")(200)	meanTitles = c("A. Phenofit: Present", "B. Phenofit: HadA2", "C. Naive SDM: Present",  "D. Naive SDM: HadA2", "G. Integrated: Present", "H. Integrated: HadA2")	errorTitles = c("E. SDM: Present SE",  "F. SDM: HadA2 SE", "I. Integrated: Present SE", "J. Integrated: HadA2 SE")	meanScaleTitle = "Suitability"	errorZlims = range(errorPredictions)	errorColors = colorRampPalette(c("#ffffff", "#ffffb2", "#fecc5c", "#fd8d3c", "#e31a1c"), interpolate='spline', space="rgb", bias=1.3)(200)	errorScaleTitle = "Posterior Standard Error"	# prepare data for contour plot	require(reshape2)	tmp = data.frame(x = longitude, y = latitude, z = meanPredictions[,3])	tmp = tmp[order(tmp$x, tmp$y),]	contourDat = list(x = unique(tmp$x), y = unique(tmp$y), z = acast(tmp, x~y, value.var='z'))	rm(tmp)#
	# produce the plot#	pdf(file=pdfFileName, width=pdfWidth,height=pdfHeight)	quartz(width=pdfWidth,height=pdfHeight)	plotLayout = matrix(c(		1,2,11,11,		1,2,12,12,		3,4,7,8,		5,6,9,10),	  byrow=T, nrow=4)	layout(plotLayout, heights=c(0.5, 0.5, 1, 1))	par(mar=c(1,1,1,1))	for(i in 1:ncol(meanPredictions)) {		quilt.plot(longitude, latitude, meanPredictions[,i], col=meanColors, zlim=meanZlims, add.legend=F, xaxt='n', yaxt='n', useRaster=T)		plot(ocean, col="white", add=T)		contour(contourDat$x, contourDat$y, contourDat$z, col='red', levels=c(0.35), add=TRUE, lwd=1.5, labels='')		mtext(meanTitles[i], adj=0, cex = titleCEX)	}	for(i in 1:ncol(errorPredictions)) {		quilt.plot(longitude, latitude, errorPredictions[,i], col=errorColors, zlim=errorZlims, add.legend=F, xaxt='n', yaxt='n', useRaster=T)		plot(ocean, col="white", add=T)		mtext(errorTitles[i], adj=0, cex = titleCEX)	}	## scale bars	par(mar=c(3,1,3,1))	image(x=seq(meanZlims[1],meanZlims[2],length.out=101), z=matrix(seq(meanZlims[1], meanZlims[2],length.out=100), 		nrow=100, ncol=1), zlim=meanZlims, col=meanColors, yaxt='n', xlab='', ylab='', useRaster=T)	mtext(meanScaleTitle, line=0.5, cex = titleCEX)	image(x=seq(errorZlims[1],errorZlims[2],length.out=101), z=matrix(seq(errorZlims[1], errorZlims[2],length.out=100), 		nrow=100, ncol=1), zlim=errorZlims, col=errorColors, yaxt='n', xlab='', ylab='', useRaster=T)	mtext(errorScaleTitle, line=0.5, cex = titleCEX)#	dev.off()}#
process_predictions = function(maple, naiveModel, intPredictions, intPosterior){##	builds an object containing the predictions of all models, both for all of the#	original data points (in result$all) and for the validation points (result$valid)##	maple: the same maple object saved in step 1#	naiveModel: the glm object representing the naive model#	intPredictions: a data frame of predictions (produced in step 4)#	intPosterior: the posterior samples from the integrated model, produced by step 3#	require(pROC)	# extract only the relevant climate variables	presClimate = maple$all[,which(colnames(maple$calib) %in% 		unique(naiveModel$variables$varNames))]	futClimate = maple$all[,which(substr(colnames(maple$calib),5, nchar(colnames(maple$calib)))		%in% unique(naiveModel$variables$varNames))]	validationClimate = maple$valid[,which(colnames(maple$calib) %in% 		unique(naiveModel$variables$varNames))]	colnames(futClimate) = colnames(presClimate)	# apply the transformations used in the calibration data to the projection datasets	presClimate = as.data.frame(sapply(names(presClimate), function(name) {		maple$transformations[[name]]$forward(presClimate[,name])}))	futClimate = as.data.frame(sapply(names(futClimate), function(name) {		maple$transformations[[name]]$forward(futClimate[,name])}))	validationClimate = as.data.frame(sapply(names(validationClimate), function(name) {		maple$transformations[[name]]$forward(validationClimate[,name])}))	# produce predictions for the naive model	naivePresPred = predict(naiveModel$model, newdata=presClimate, type='response', se.fit=TRUE)	naiveFutPred = predict(naiveModel$model, newdata=futClimate, type='response', se.fit=TRUE)	naiveValidPred = predict(naiveModel$model, newdata=validationClimate, type='response', se.fit=FALSE)	# wrap everything into a data frame	predictions = cbind(maple$all[,1:2], naivePresPred$fit, naivePresPred$se.fit, 		naiveFutPred$fit, naiveFutPred$se.fit, intPredictions)	colnames(predictions) = c("long", "lat", 		'naivePresent', 'naivePresentSE', 'naiveFuture', 'naiveFutureSE',		'intPresent', 'intPresentSE', 'intPresentLower', 'intPresentUpper',		'intFuture', 'intFutureSE', 'intFutureLower', 'intFutureUpper')	# validation	intValidPred = predict_mcmc(intPosterior, validationClimate)	validation = list(data = cbind(maple$valid[,1:5], naiveValidPred, intValidPred))	colnames(validation$data) = c('long', 'lat', 'presence', 'phenofitPres', 'phenofitFut', 'naive', 'integrated')	validation$naiveROC = roc(validation$data$presence, validation$data$naive)	validation$phenofitROC = roc(validation$data$presence, validation$data$phenofitPres)	validation$integratedROC = roc(validation$data$presence, validation$data$integrated)#
	return(list(all=predictions, valid=validation))}#
predict_mcmc = function(posteriorSample, newData) {##	Works like predict(), but for mcmc samples#	Returns the average prediction for each point in the new dataset#	#	posteriorSample: mcmc object; the posterior sample from which to produce predictions#	newData: data frame of predictors where predictions should be produced#	parPrefix = 2	parEnd = 1	#
	# predict the prob of presence for each point in newData	# assumes the FIRST parameter in posteriorSample is the intercept	predictedPrPresenceMean = mean(posteriorSample[,1])	currentCol = 2	while(currentCol <= ncol(posteriorSample)) {		ndColumn = which(colnames(newData) == substr(colnames(posteriorSample)[currentCol], parPrefix + 1, nchar(colnames(posteriorSample)[currentCol]) - parEnd))		exponent = as.integer(substr(colnames(posteriorSample)[currentCol], nchar(colnames(posteriorSample)[currentCol]), nchar(colnames(posteriorSample)[currentCol])))		predictedPrPresenceMean = predictedPrPresenceMean + mean(posteriorSample[,currentCol]) * newData[,ndColumn]^exponent				currentCol = currentCol + 1	}	predictedPrPresenceMean = inv_logit(predictedPrPresenceMean)		return(predictedPrPresenceMean)}#
inv_logit = function(x) {	inf.ind = which(x == Inf)		# negative infinity works normally, but Inf returns NaN	result = exp(x) / (1+exp(x))	result[inf.ind] = 1	return(result)}in.range = function(x, lims) x >= lims[1] & x <= lims[2]#
main()
# 5-make_figure.r# #   Copyright 2014 Matthew V Talluto, Isabelle Boulangeat, Dominique Gravel# #   This program is free software; you can redistribute it and/or modify#   it under the terms of the GNU General Public License as published by#   the Free Software Foundation; either version 3 of the License, or (at#   your option) any later version.#   #   This program is distributed in the hope that it will be useful, but#   WITHOUT ANY WARRANTY; without even the implied warranty of#   MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU#   General Public License for more details.# #   You should have received a copy of the GNU General Public License#   along with this program; if not, write to the Free Software#   Foundation, Inc., 51 Franklin Street, Fifth Floor, Boston, MA 02110-1301, USA.##### produce the figure for the second example###
main = function(){	require(fields)	require(rgdal)	require(coda)#
	load("dat/naive_model.rdata")	intPredictions = read.csv("results/integratedStats.csv")	load("results/integratedModel.rdata")#
	predictions = process_predictions(maple, naiveModel, intPredictions, integratedModel)	ocean = readOGR(dsn="dat/ne_110m_ocean", layer="ne_110m_ocean")	pdfFileName = "ex2.pdf"	pdfWidth = 7.5	pdfHeight = 6	titleCEX = 0.7#
	# which columns to loop thru for mean and errors	meanCols = c(3,5,7,11)	SECols = meanCols + 1	## pick the data to display	latLimits = c(27,65)	longLimits = c(-105, -55)	predictionsSub = subset(predictions$all, in.range(lat, latLimits) & in.range(long, longLimits))	mapleAllSub = subset(maple$all, in.range(lat, latLimits) & in.range(long, longLimits))	latitude = predictionsSub[,2]	longitude = predictionsSub[,1]	meanPredictions = cbind(mapleAllSub$Phenofit_CRU, mapleAllSub$Phenofit_HadA2, predictionsSub[,meanCols])	errorPredictions = predictionsSub[,SECols]	## plotting settings	meanZlims = c(0,1)	meanColors = colorRampPalette(c("#ffffff", "#bdc9e1", "#045a8d", "#33338d", "#cc99ff"), interpolate='spline', bias=1, space="rgb")(200)	meanTitles = c("A. Phenofit: Present", "B. Phenofit: HadA2", "C. Naive SDM: Present",  "D. Naive SDM: HadA2", "G. Integrated: Present", "H. Integrated: HadA2")	errorTitles = c("E. SDM: Present SE",  "F. SDM: HadA2 SE", "I. Integrated: Present SE", "J. Integrated: HadA2 SE")	meanScaleTitle = "Suitability"	errorZlims = range(errorPredictions)	errorColors = colorRampPalette(c("#ffffff", "#ffffb2", "#fecc5c", "#fd8d3c", "#e31a1c"), interpolate='spline', space="rgb", bias=1.3)(200)	errorScaleTitle = "Posterior Standard Error"	# prepare data for contour plot	require(reshape2)	tmp = data.frame(x = longitude, y = latitude, z = meanPredictions[,3])	tmp = data.frame(x = longitude, y = latitude, z = meanPredictions[,1])	tmp = tmp[order(tmp$x, tmp$y),]	contourDat = list(x = unique(tmp$x), y = unique(tmp$y), z = acast(tmp, x~y, value.var='z'))	rm(tmp)#
	# produce the plot#	pdf(file=pdfFileName, width=pdfWidth,height=pdfHeight)	quartz(width=pdfWidth,height=pdfHeight)	plotLayout = matrix(c(		1,2,11,11,		1,2,12,12,		3,4,7,8,		5,6,9,10),	  byrow=T, nrow=4)	layout(plotLayout, heights=c(0.5, 0.5, 1, 1))	par(mar=c(1,1,1,1))	for(i in 1:ncol(meanPredictions)) {		quilt.plot(longitude, latitude, meanPredictions[,i], col=meanColors, zlim=meanZlims, add.legend=F, xaxt='n', yaxt='n', useRaster=T)		plot(ocean, col="white", add=T)		contour(contourDat$x, contourDat$y, contourDat$z, col='red', levels=c(0.35), add=TRUE, lwd=1.5, labels='')		mtext(meanTitles[i], adj=0, cex = titleCEX)	}	for(i in 1:ncol(errorPredictions)) {		quilt.plot(longitude, latitude, errorPredictions[,i], col=errorColors, zlim=errorZlims, add.legend=F, xaxt='n', yaxt='n', useRaster=T)		plot(ocean, col="white", add=T)		mtext(errorTitles[i], adj=0, cex = titleCEX)	}	## scale bars	par(mar=c(3,1,3,1))	image(x=seq(meanZlims[1],meanZlims[2],length.out=101), z=matrix(seq(meanZlims[1], meanZlims[2],length.out=100), 		nrow=100, ncol=1), zlim=meanZlims, col=meanColors, yaxt='n', xlab='', ylab='', useRaster=T)	mtext(meanScaleTitle, line=0.5, cex = titleCEX)	image(x=seq(errorZlims[1],errorZlims[2],length.out=101), z=matrix(seq(errorZlims[1], errorZlims[2],length.out=100), 		nrow=100, ncol=1), zlim=errorZlims, col=errorColors, yaxt='n', xlab='', ylab='', useRaster=T)	mtext(errorScaleTitle, line=0.5, cex = titleCEX)#	dev.off()}#
process_predictions = function(maple, naiveModel, intPredictions, intPosterior){##	builds an object containing the predictions of all models, both for all of the#	original data points (in result$all) and for the validation points (result$valid)##	maple: the same maple object saved in step 1#	naiveModel: the glm object representing the naive model#	intPredictions: a data frame of predictions (produced in step 4)#	intPosterior: the posterior samples from the integrated model, produced by step 3#	require(pROC)	# extract only the relevant climate variables	presClimate = maple$all[,which(colnames(maple$calib) %in% 		unique(naiveModel$variables$varNames))]	futClimate = maple$all[,which(substr(colnames(maple$calib),5, nchar(colnames(maple$calib)))		%in% unique(naiveModel$variables$varNames))]	validationClimate = maple$valid[,which(colnames(maple$calib) %in% 		unique(naiveModel$variables$varNames))]	colnames(futClimate) = colnames(presClimate)	# apply the transformations used in the calibration data to the projection datasets	presClimate = as.data.frame(sapply(names(presClimate), function(name) {		maple$transformations[[name]]$forward(presClimate[,name])}))	futClimate = as.data.frame(sapply(names(futClimate), function(name) {		maple$transformations[[name]]$forward(futClimate[,name])}))	validationClimate = as.data.frame(sapply(names(validationClimate), function(name) {		maple$transformations[[name]]$forward(validationClimate[,name])}))	# produce predictions for the naive model	naivePresPred = predict(naiveModel$model, newdata=presClimate, type='response', se.fit=TRUE)	naiveFutPred = predict(naiveModel$model, newdata=futClimate, type='response', se.fit=TRUE)	naiveValidPred = predict(naiveModel$model, newdata=validationClimate, type='response', se.fit=FALSE)	# wrap everything into a data frame	predictions = cbind(maple$all[,1:2], naivePresPred$fit, naivePresPred$se.fit, 		naiveFutPred$fit, naiveFutPred$se.fit, intPredictions)	colnames(predictions) = c("long", "lat", 		'naivePresent', 'naivePresentSE', 'naiveFuture', 'naiveFutureSE',		'intPresent', 'intPresentSE', 'intPresentLower', 'intPresentUpper',		'intFuture', 'intFutureSE', 'intFutureLower', 'intFutureUpper')	# validation	intValidPred = predict_mcmc(intPosterior, validationClimate)	validation = list(data = cbind(maple$valid[,1:5], naiveValidPred, intValidPred))	colnames(validation$data) = c('long', 'lat', 'presence', 'phenofitPres', 'phenofitFut', 'naive', 'integrated')	validation$naiveROC = roc(validation$data$presence, validation$data$naive)	validation$phenofitROC = roc(validation$data$presence, validation$data$phenofitPres)	validation$integratedROC = roc(validation$data$presence, validation$data$integrated)#
	return(list(all=predictions, valid=validation))}#
predict_mcmc = function(posteriorSample, newData) {##	Works like predict(), but for mcmc samples#	Returns the average prediction for each point in the new dataset#	#	posteriorSample: mcmc object; the posterior sample from which to produce predictions#	newData: data frame of predictors where predictions should be produced#	parPrefix = 2	parEnd = 1	#
	# predict the prob of presence for each point in newData	# assumes the FIRST parameter in posteriorSample is the intercept	predictedPrPresenceMean = mean(posteriorSample[,1])	currentCol = 2	while(currentCol <= ncol(posteriorSample)) {		ndColumn = which(colnames(newData) == substr(colnames(posteriorSample)[currentCol], parPrefix + 1, nchar(colnames(posteriorSample)[currentCol]) - parEnd))		exponent = as.integer(substr(colnames(posteriorSample)[currentCol], nchar(colnames(posteriorSample)[currentCol]), nchar(colnames(posteriorSample)[currentCol])))		predictedPrPresenceMean = predictedPrPresenceMean + mean(posteriorSample[,currentCol]) * newData[,ndColumn]^exponent				currentCol = currentCol + 1	}	predictedPrPresenceMean = inv_logit(predictedPrPresenceMean)		return(predictedPrPresenceMean)}#
inv_logit = function(x) {	inf.ind = which(x == Inf)		# negative infinity works normally, but Inf returns NaN	result = exp(x) / (1+exp(x))	result[inf.ind] = 1	return(result)}in.range = function(x, lims) x >= lims[1] & x <= lims[2]#
main()
# 5-make_figure.r# #   Copyright 2014 Matthew V Talluto, Isabelle Boulangeat, Dominique Gravel# #   This program is free software; you can redistribute it and/or modify#   it under the terms of the GNU General Public License as published by#   the Free Software Foundation; either version 3 of the License, or (at#   your option) any later version.#   #   This program is distributed in the hope that it will be useful, but#   WITHOUT ANY WARRANTY; without even the implied warranty of#   MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU#   General Public License for more details.# #   You should have received a copy of the GNU General Public License#   along with this program; if not, write to the Free Software#   Foundation, Inc., 51 Franklin Street, Fifth Floor, Boston, MA 02110-1301, USA.##### produce the figure for the second example###
main = function(){	require(fields)	require(rgdal)	require(coda)#
	load("dat/naive_model.rdata")	intPredictions = read.csv("results/integratedStats.csv")	load("results/integratedModel.rdata")#
	predictions = process_predictions(maple, naiveModel, intPredictions, integratedModel)	ocean = readOGR(dsn="dat/ne_110m_ocean", layer="ne_110m_ocean")	pdfFileName = "ex2.pdf"	pdfWidth = 7.5	pdfHeight = 6	titleCEX = 0.7#
	# which columns to loop thru for mean and errors	meanCols = c(3,5,7,11)	SECols = meanCols + 1	## pick the data to display	latLimits = c(27,65)	longLimits = c(-105, -55)	predictionsSub = subset(predictions$all, in.range(lat, latLimits) & in.range(long, longLimits))	mapleAllSub = subset(maple$all, in.range(lat, latLimits) & in.range(long, longLimits))	latitude = predictionsSub[,2]	longitude = predictionsSub[,1]	meanPredictions = cbind(mapleAllSub$Phenofit_CRU, mapleAllSub$Phenofit_HadA2, predictionsSub[,meanCols])	errorPredictions = predictionsSub[,SECols]	## plotting settings	meanZlims = c(0,1)	meanColors = colorRampPalette(c("#ffffff", "#bdc9e1", "#045a8d", "#33338d", "#cc99ff"), interpolate='spline', bias=1, space="rgb")(200)	meanTitles = c("A. Phenofit: Present", "B. Phenofit: HadA2", "C. Naive SDM: Present",  "D. Naive SDM: HadA2", "G. Integrated: Present", "H. Integrated: HadA2")	errorTitles = c("E. SDM: Present SE",  "F. SDM: HadA2 SE", "I. Integrated: Present SE", "J. Integrated: HadA2 SE")	meanScaleTitle = "Suitability"	errorZlims = range(errorPredictions)	errorColors = colorRampPalette(c("#ffffff", "#ffffb2", "#fecc5c", "#fd8d3c", "#e31a1c"), interpolate='spline', space="rgb", bias=1.3)(200)	errorScaleTitle = "Posterior Standard Error"	# prepare data for contour plot	require(reshape2)	asRange = readOGR(dsn="dat/acerspic", layer="acerspic")	tmp = data.frame(x = longitude, y = latitude, z = meanPredictions[,3])	tmp = data.frame(x = longitude, y = latitude, z = meanPredictions[,1])	tmp = tmp[order(tmp$x, tmp$y),]	contourDat = list(x = unique(tmp$x), y = unique(tmp$y), z = acast(tmp, x~y, value.var='z'))	rm(tmp)#
	# produce the plot#	pdf(file=pdfFileName, width=pdfWidth,height=pdfHeight)	quartz(width=pdfWidth,height=pdfHeight)	plotLayout = matrix(c(		1,2,11,11,		1,2,12,12,		3,4,7,8,		5,6,9,10),	  byrow=T, nrow=4)	layout(plotLayout, heights=c(0.5, 0.5, 1, 1))	par(mar=c(1,1,1,1))	for(i in 1:ncol(meanPredictions)) {		quilt.plot(longitude, latitude, meanPredictions[,i], col=meanColors, zlim=meanZlims, add.legend=F, xaxt='n', yaxt='n', useRaster=T)		plot(ocean, col="white", add=T)		contour(contourDat$x, contourDat$y, contourDat$z, col='red', levels=c(0.35), add=TRUE, lwd=1.5, labels='')		plot(asRange, col="black", add=T)		mtext(meanTitles[i], adj=0, cex = titleCEX)	}	for(i in 1:ncol(errorPredictions)) {		quilt.plot(longitude, latitude, errorPredictions[,i], col=errorColors, zlim=errorZlims, add.legend=F, xaxt='n', yaxt='n', useRaster=T)		plot(ocean, col="white", add=T)		mtext(errorTitles[i], adj=0, cex = titleCEX)	}	## scale bars	par(mar=c(3,1,3,1))	image(x=seq(meanZlims[1],meanZlims[2],length.out=101), z=matrix(seq(meanZlims[1], meanZlims[2],length.out=100), 		nrow=100, ncol=1), zlim=meanZlims, col=meanColors, yaxt='n', xlab='', ylab='', useRaster=T)	mtext(meanScaleTitle, line=0.5, cex = titleCEX)	image(x=seq(errorZlims[1],errorZlims[2],length.out=101), z=matrix(seq(errorZlims[1], errorZlims[2],length.out=100), 		nrow=100, ncol=1), zlim=errorZlims, col=errorColors, yaxt='n', xlab='', ylab='', useRaster=T)	mtext(errorScaleTitle, line=0.5, cex = titleCEX)#	dev.off()}#
process_predictions = function(maple, naiveModel, intPredictions, intPosterior){##	builds an object containing the predictions of all models, both for all of the#	original data points (in result$all) and for the validation points (result$valid)##	maple: the same maple object saved in step 1#	naiveModel: the glm object representing the naive model#	intPredictions: a data frame of predictions (produced in step 4)#	intPosterior: the posterior samples from the integrated model, produced by step 3#	require(pROC)	# extract only the relevant climate variables	presClimate = maple$all[,which(colnames(maple$calib) %in% 		unique(naiveModel$variables$varNames))]	futClimate = maple$all[,which(substr(colnames(maple$calib),5, nchar(colnames(maple$calib)))		%in% unique(naiveModel$variables$varNames))]	validationClimate = maple$valid[,which(colnames(maple$calib) %in% 		unique(naiveModel$variables$varNames))]	colnames(futClimate) = colnames(presClimate)	# apply the transformations used in the calibration data to the projection datasets	presClimate = as.data.frame(sapply(names(presClimate), function(name) {		maple$transformations[[name]]$forward(presClimate[,name])}))	futClimate = as.data.frame(sapply(names(futClimate), function(name) {		maple$transformations[[name]]$forward(futClimate[,name])}))	validationClimate = as.data.frame(sapply(names(validationClimate), function(name) {		maple$transformations[[name]]$forward(validationClimate[,name])}))	# produce predictions for the naive model	naivePresPred = predict(naiveModel$model, newdata=presClimate, type='response', se.fit=TRUE)	naiveFutPred = predict(naiveModel$model, newdata=futClimate, type='response', se.fit=TRUE)	naiveValidPred = predict(naiveModel$model, newdata=validationClimate, type='response', se.fit=FALSE)	# wrap everything into a data frame	predictions = cbind(maple$all[,1:2], naivePresPred$fit, naivePresPred$se.fit, 		naiveFutPred$fit, naiveFutPred$se.fit, intPredictions)	colnames(predictions) = c("long", "lat", 		'naivePresent', 'naivePresentSE', 'naiveFuture', 'naiveFutureSE',		'intPresent', 'intPresentSE', 'intPresentLower', 'intPresentUpper',		'intFuture', 'intFutureSE', 'intFutureLower', 'intFutureUpper')	# validation	intValidPred = predict_mcmc(intPosterior, validationClimate)	validation = list(data = cbind(maple$valid[,1:5], naiveValidPred, intValidPred))	colnames(validation$data) = c('long', 'lat', 'presence', 'phenofitPres', 'phenofitFut', 'naive', 'integrated')	validation$naiveROC = roc(validation$data$presence, validation$data$naive)	validation$phenofitROC = roc(validation$data$presence, validation$data$phenofitPres)	validation$integratedROC = roc(validation$data$presence, validation$data$integrated)#
	return(list(all=predictions, valid=validation))}#
predict_mcmc = function(posteriorSample, newData) {##	Works like predict(), but for mcmc samples#	Returns the average prediction for each point in the new dataset#	#	posteriorSample: mcmc object; the posterior sample from which to produce predictions#	newData: data frame of predictors where predictions should be produced#	parPrefix = 2	parEnd = 1	#
	# predict the prob of presence for each point in newData	# assumes the FIRST parameter in posteriorSample is the intercept	predictedPrPresenceMean = mean(posteriorSample[,1])	currentCol = 2	while(currentCol <= ncol(posteriorSample)) {		ndColumn = which(colnames(newData) == substr(colnames(posteriorSample)[currentCol], parPrefix + 1, nchar(colnames(posteriorSample)[currentCol]) - parEnd))		exponent = as.integer(substr(colnames(posteriorSample)[currentCol], nchar(colnames(posteriorSample)[currentCol]), nchar(colnames(posteriorSample)[currentCol])))		predictedPrPresenceMean = predictedPrPresenceMean + mean(posteriorSample[,currentCol]) * newData[,ndColumn]^exponent				currentCol = currentCol + 1	}	predictedPrPresenceMean = inv_logit(predictedPrPresenceMean)		return(predictedPrPresenceMean)}#
inv_logit = function(x) {	inf.ind = which(x == Inf)		# negative infinity works normally, but Inf returns NaN	result = exp(x) / (1+exp(x))	result[inf.ind] = 1	return(result)}in.range = function(x, lims) x >= lims[1] & x <= lims[2]#
main()
# prepare data for contour plot	require(reshape2)	asRange = readOGR(dsn="dat/acerspic", layer="acerspic")	tmp = data.frame(x = longitude, y = latitude, z = meanPredictions[,3])	tmp = data.frame(x = longitude, y = latitude, z = meanPredictions[,1])	tmp = tmp[order(tmp$x, tmp$y),]	contourDat = list(x = unique(tmp$x), y = unique(tmp$y), z = acast(tmp, x~y, value.var='z'))	rm(tmp)	quilt.plot(longitude, latitude, meanPredictions[,3], col=meanColors, zlim=meanZlims, add.legend=F, xaxt='n', yaxt='n', useRaster=T)	plot(ocean, col="white", add=T)	contour(contourDat$x, contourDat$y, contourDat$z, col='red', levels=c(0.35), add=TRUE, lwd=1.5, labels='')	plot(asRange, col="#444444aa", add=T)
require(reshape2)	asRange = readOGR(dsn="dat/acersacr", layer="acersacr")	tmp = data.frame(x = longitude, y = latitude, z = meanPredictions[,3])	tmp = data.frame(x = longitude, y = latitude, z = meanPredictions[,1])	tmp = tmp[order(tmp$x, tmp$y),]	contourDat = list(x = unique(tmp$x), y = unique(tmp$y), z = acast(tmp, x~y, value.var='z'))	rm(tmp)	quilt.plot(longitude, latitude, meanPredictions[,3], col=meanColors, zlim=meanZlims, add.legend=F, xaxt='n', yaxt='n', useRaster=T)	plot(ocean, col="white", add=T)	contour(contourDat$x, contourDat$y, contourDat$z, col='red', levels=c(0.35), add=TRUE, lwd=1.5, labels='')	plot(asRange, col="#444444aa", add=T)
quilt.plot(longitude, latitude, meanPredictions[,3], col=meanColors, zlim=meanZlims, add.legend=F, xaxt='n', yaxt='n', useRaster=T)	plot(asRange, col="#444444aa", add=T)	plot(ocean, col="white", add=T)
quilt.plot(longitude, latitude, meanPredictions[,3], col=meanColors, zlim=meanZlims, add.legend=F, xaxt='n', yaxt='n', useRaster=T)	plot(asRange, col="white", add=T)	plot(ocean, col="white", add=T)
class(asRange)
?plot
?"plot"
?sp
asTest = SpatialLines(asRange)
slots(asRange)
asTest = SpatialPolygons(asRange)
quilt.plot(longitude, latitude, meanPredictions[,3], col=meanColors, zlim=meanZlims, add.legend=F, xaxt='n', yaxt='n', useRaster=T)	plot(asRange, border='red', col="FF0000FF", add=T)	plot(ocean, col="white", add=T)
quilt.plot(longitude, latitude, meanPredictions[,3], col=meanColors, zlim=meanZlims, add.legend=F, xaxt='n', yaxt='n', useRaster=T)	plot(asRange, border='red', col="#FF0000FF", add=T)	plot(ocean, col="white", add=T)
quilt.plot(longitude, latitude, meanPredictions[,3], col=meanColors, zlim=meanZlims, add.legend=F, xaxt='n', yaxt='n', useRaster=T)	plot(asRange, border='red', col="#FF5555FF", add=T)	plot(ocean, col="white", add=T)
quilt.plot(longitude, latitude, meanPredictions[,3], col=meanColors, zlim=meanZlims, add.legend=F, xaxt='n', yaxt='n', useRaster=T)	plot(asRange, border='red', col="#FF555500", add=T)	plot(ocean, col="white", add=T)
# prepare data for contour plot	require(reshape2)	asRange = readOGR(dsn="dat/acersacr", layer="acersacr")	coast = readOGR(dsn="dat/ne_10m_coastline", layer="ne_10m_coastline")	tmp = data.frame(x = longitude, y = latitude, z = meanPredictions[,3])	tmp = data.frame(x = longitude, y = latitude, z = meanPredictions[,1])	tmp = tmp[order(tmp$x, tmp$y),]	contourDat = list(x = unique(tmp$x), y = unique(tmp$y), z = acast(tmp, x~y, value.var='z'))	rm(tmp)	quilt.plot(longitude, latitude, meanPredictions[,3], col=meanColors, zlim=meanZlims, add.legend=F, xaxt='n', yaxt='n', useRaster=T)	plot(asRange, border='red', col="#FF555500", add=T)	plot(coast, col="black", add=T)
require(reshape2)	asRange = readOGR(dsn="dat/acersacr", layer="acersacr")	ocean2 = readOGR(dsn="dat/ne_10m_ocean", layer="ne_10m_ocean")	tmp = data.frame(x = longitude, y = latitude, z = meanPredictions[,3])	tmp = data.frame(x = longitude, y = latitude, z = meanPredictions[,1])	tmp = tmp[order(tmp$x, tmp$y),]	contourDat = list(x = unique(tmp$x), y = unique(tmp$y), z = acast(tmp, x~y, value.var='z'))	rm(tmp)	quilt.plot(longitude, latitude, meanPredictions[,3], col=meanColors, zlim=meanZlims, add.legend=F, xaxt='n', yaxt='n', useRaster=T)	plot(asRange, border='red', col="#FF555500", add=T)	plot(ocean2, col="white", add=T)
# prepare data for contour plot	require(reshape2)	asRange = readOGR(dsn="dat/acersacr", layer="acersacr")	ocean2 = readOGR(dsn="dat/ne_10m_ocean", layer="ne_10m_ocean")	lakes = readOGR(dsn="dat/ne_10m_lakes", layer="ne_10m_lakes")	tmp = data.frame(x = longitude, y = latitude, z = meanPredictions[,3])	tmp = data.frame(x = longitude, y = latitude, z = meanPredictions[,1])	tmp = tmp[order(tmp$x, tmp$y),]	contourDat = list(x = unique(tmp$x), y = unique(tmp$y), z = acast(tmp, x~y, value.var='z'))	rm(tmp)	quilt.plot(longitude, latitude, meanPredictions[,3], col=meanColors, zlim=meanZlims, add.legend=F, xaxt='n', yaxt='n', useRaster=T)	plot(asRange, border='red', col="#FF555500", add=T)	plot(ocean2, col="white", add=T)	plot(lakes, col="yellow", add=T)
str(lakes)
nrow(lakes)
colnames(lakes)
names(lakes)
lakes$name
which(lakes$names == "Lake Michigan")
which("Huron" %in% lakes$names)
which(lakes$names == "Michigan")
head(lakes$names)
lakes$name
which(lakes$name == "Michigan")
which(lakes$name == "Lake Michigan")
plot(lakes[467])
plot(lakes[467,])
names = c("Lake Huron", "Lake Michigan", "Lake Superior", "Lake Ontario", "Lake Eire")
which(names %in% lakes$name)
which(lakes$name == names)
which(lakes$name %in% names)
# prepare data for contour plot	require(reshape2)	asRange = readOGR(dsn="dat/acersacr", layer="acersacr")	ocean2 = readOGR(dsn="dat/ne_10m_ocean", layer="ne_10m_ocean")	lakes = readOGR(dsn="dat/ne_10m_lakes", layer="ne_10m_lakes")	# grab specific lakes	lkNames = c("Lake Huron", "Lake Michigan", "Lake Superior", "Lake Ontario", "Lake Eire")	grLakes = lakes[which(lakes$name %in% lkNames))	tmp = data.frame(x = longitude, y = latitude, z = meanPredictions[,3])	tmp = data.frame(x = longitude, y = latitude, z = meanPredictions[,1])	tmp = tmp[order(tmp$x, tmp$y),]	contourDat = list(x = unique(tmp$x), y = unique(tmp$y), z = acast(tmp, x~y, value.var='z'))	rm(tmp)	quilt.plot(longitude, latitude, meanPredictions[,3], col=meanColors, zlim=meanZlims, add.legend=F, xaxt='n', yaxt='n', useRaster=T)	plot(asRange, border='red', col="#FF555500", add=T)	plot(ocean2, col="white", add=T)	plot(grLakes, col="yellow", add=T)
grLakes = lakes[which(lakes$name %in% lkNames)]
plot(grLakes, col="yellow", add=T)
grLakes = lakes[which(lakes$name %in% lkNames),]
plot(grLakes, col="yellow", add=T)
lkNames = c("Lake Huron", "Lake Michigan", "Lake Superior", "Lake Ontario", "Lake Erie")	grLakes = lakes[which(lakes$name %in% lkNames),]	tmp = data.frame(x = longitude, y = latitude, z = meanPredictions[,3])	tmp = data.frame(x = longitude, y = latitude, z = meanPredictions[,1])	tmp = tmp[order(tmp$x, tmp$y),]	contourDat = list(x = unique(tmp$x), y = unique(tmp$y), z = acast(tmp, x~y, value.var='z'))	rm(tmp)	quilt.plot(longitude, latitude, meanPredictions[,3], col=meanColors, zlim=meanZlims, add.legend=F, xaxt='n', yaxt='n', useRaster=T)	plot(asRange, border='red', col="#FF555500", add=T)	plot(ocean2, col="white", add=T)	plot(grLakes, col="yellow", add=T)
lkNames = c("Lake Huron", "Lake Michigan", "Lake Superior", "Lake Ontario", "Lake Erie", "Lake St Claire")
grLakes = lakes[which(lakes$name %in% lkNames),]
nrow(grLakes)
sapply(lakes$name, function(x) "Claire" %in% x)
which(sapply(lakes$name, function(x) "Claire" %in% x))
which(sapply(lakes$name, function(x) "Clair" %in% x))
lakes$name
which(sapply(lakes$name, function(x) "Salton" %in% x))
grep
grep("Salton", lakes$name)
grep("Clair", lakes$name)
lake$name[grep("Clair", lakes$name)]
lakes$name[grep("Clair", lakes$name)]
# grab specific lakes	lkNames = c("Lake Huron", "Lake Michigan", "Lake Superior", "Lake Ontario", "Lake Erie", "Lake St. Clair")	grLakes = lakes[which(lakes$name %in% lkNames),]	tmp = data.frame(x = longitude, y = latitude, z = meanPredictions[,3])	tmp = data.frame(x = longitude, y = latitude, z = meanPredictions[,1])	tmp = tmp[order(tmp$x, tmp$y),]	contourDat = list(x = unique(tmp$x), y = unique(tmp$y), z = acast(tmp, x~y, value.var='z'))	rm(tmp)	quilt.plot(longitude, latitude, meanPredictions[,3], col=meanColors, zlim=meanZlims, add.legend=F, xaxt='n', yaxt='n', useRaster=T)	plot(asRange, border='red', col="#FF555500", add=T)	plot(ocean2, col="white", add=T)	plot(grLakes, col="yellow", add=T)
lkNames = c("Lake Huron", "Lake Michigan", "Lake Superior", "Lake Ontario", "Lake Erie", "Lake St. Clair", "Lake George", "Lake Nicolet")	grLakes = lakes[which(lakes$name %in% lkNames),]	tmp = data.frame(x = longitude, y = latitude, z = meanPredictions[,3])	tmp = data.frame(x = longitude, y = latitude, z = meanPredictions[,1])	tmp = tmp[order(tmp$x, tmp$y),]	contourDat = list(x = unique(tmp$x), y = unique(tmp$y), z = acast(tmp, x~y, value.var='z'))	rm(tmp)	quilt.plot(longitude, latitude, meanPredictions[,3], col=meanColors, zlim=meanZlims, add.legend=F, xaxt='n', yaxt='n', useRaster=T)	plot(asRange, border='red', col="#FF555500", add=T)	plot(ocean2, col="white", add=T)	plot(grLakes, col="yellow", add=T)
nrow(grLakes)
grLakes$name
grep("George", lakes$name)
lakes$name[grep("George", lakes$name)]
lakes$name[grep("Nicolet", lakes$name)]
lakes$name[grep("Munoscong", lakes$name)]
quilt.plot(longitude, latitude, meanPredictions[,3], col=meanColors, zlim=meanZlims, add.legend=F, xaxt='n', yaxt='n', useRaster=T)	plot(asRange, border='red', col="#FF555500", add=T)	plot(ocean2, col="white", add=T)	plot(grLakes, col="white", add=T)
names(asRange)
nrow(asRange)
plot(asRange[1:100])
plot(asRange[1:100,])
plot(asRange[1:50,])
plot(asRange[1,])
plot(asRange[2,])
plot(asRange[1:2,])
plot(asRange[1:10,])
plot(asRange[1:100,])
plot(asRange[1:10,])
plot(asRange[c(1,3),])
plot(asRange[c(1),])
plot(asRange[c(1,3),])
plot(asRange[c(1,3,4),])
plot(asRange[c(1,3,5),])
plot(asRange[c(1,3,6),])
plot(asRange[c(1,3,7),])
plot(asRange[c(1,3,8),])
plot(asRange[c(1,3,9),])
plot(asRange[c(1,3,10),])
plot(asRange[1:10,])
plot(asRange[1:20,])
plot(asRange[1:30,])
plot(asRange[1:40,])
plot(asRange[1:50,])
plot(asRange[c(1,3,50),])
plot(asRange[c(1,3,49),])
plot(asRange[c(1,3,48),])
plot(asRange[c(1,3,47),])
plot(asRange[c(1,3,47,46),])
plot(asRange[c(1,3,47,45),])
plot(asRange[c(1,3,47,44),])
plot(asRange[c(1,3,47,43),])
tmp = data.frame(x = longitude, y = latitude, z = meanPredictions[,3])	tmp = data.frame(x = longitude, y = latitude, z = meanPredictions[,1])	tmp = tmp[order(tmp$x, tmp$y),]	contourDat = list(x = unique(tmp$x), y = unique(tmp$y), z = acast(tmp, x~y, value.var='z'))	rm(tmp)	quilt.plot(longitude, latitude, meanPredictions[,3], col=meanColors, zlim=meanZlims, add.legend=F, xaxt='n', yaxt='n', useRaster=T)	plot(asRange[c(1,3,47,43),], border='red', col="#FF555500", add=T)	plot(grLakes, col="white", add=T)
plot(ocean, col="white", add=T)
plot(ocea2n, col="white", add=T)
plot(ocean2, col="white", add=T)
lkNames = c("Lake Huron", "Lake Michigan", "Lake Superior", "Lake Ontario", "Lake Erie", "Lake St. Clair", "Lake of the Woods", "Lac St. Jean")	grLakes = lakes[which(lakes$name %in% lkNames),]#
	quilt.plot(longitude, latitude, meanPredictions[,3], col=meanColors, zlim=meanZlims, add.legend=F, xaxt='n', yaxt='n', useRaster=T)	plot(asRange[c(1,3,47,43),], border='red', col="#FF555500", add=T)	plot(grLakes, col="white", add=T)	plot(ocean2, col="white", add=T)
lakes$name[grep("Jean", lakes$name)]
lkNames = c("Lake Huron", "Lake Michigan", "Lake Superior", "Lake Ontario", "Lake Erie", "Lake St. Clair", "Lake of the Woods", "Lac St.-Jean")	grLakes = lakes[which(lakes$name %in% lkNames),]#
	quilt.plot(longitude, latitude, meanPredictions[,3], col=meanColors, zlim=meanZlims, add.legend=F, xaxt='n', yaxt='n', useRaster=T)	plot(asRange[c(1,3,47,43),], border='red', col="#FF555500", add=T)	plot(grLakes, col="white", add=T)	plot(ocean2, col="white", add=T)
# 5-make_figure.r# #   Copyright 2014 Matthew V Talluto, Isabelle Boulangeat, Dominique Gravel# #   This program is free software; you can redistribute it and/or modify#   it under the terms of the GNU General Public License as published by#   the Free Software Foundation; either version 3 of the License, or (at#   your option) any later version.#   #   This program is distributed in the hope that it will be useful, but#   WITHOUT ANY WARRANTY; without even the implied warranty of#   MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU#   General Public License for more details.# #   You should have received a copy of the GNU General Public License#   along with this program; if not, write to the Free Software#   Foundation, Inc., 51 Franklin Street, Fifth Floor, Boston, MA 02110-1301, USA.##### produce the figure for the second example###
main = function(){	require(fields)	require(rgdal)	require(coda)#
	load("dat/naive_model.rdata")	intPredictions = read.csv("results/integratedStats.csv")	load("results/integratedModel.rdata")#
	predictions = process_predictions(maple, naiveModel, intPredictions, integratedModel)	ocean = readOGR(dsn="dat/ne_10m_ocean", layer="ne_10m_ocean")	mapleRange = readOGR(dsn="dat/acersacr", layer="acersacr")	lakes = readOGR(dsn="dat/ne_10m_lakes", layer="ne_10m_lakes")	# grab specific lakes	lkNames = c("Lake Huron", "Lake Michigan", "Lake Superior", "Lake Ontario", "Lake Erie", "Lake St. Clair")	grLakes = lakes[which(lakes$name %in% lkNames),]	pdfFileName = "ex2.pdf"	pdfWidth = 7.5	pdfHeight = 6	titleCEX = 0.7#
	# which columns to loop thru for mean and errors	meanCols = c(3,5,7,11)	SECols = meanCols + 1	## pick the data to display	latLimits = c(27,65)	longLimits = c(-105, -55)	predictionsSub = subset(predictions$all, in.range(lat, latLimits) & in.range(long, longLimits))	mapleAllSub = subset(maple$all, in.range(lat, latLimits) & in.range(long, longLimits))	latitude = predictionsSub[,2]	longitude = predictionsSub[,1]	meanPredictions = cbind(mapleAllSub$Phenofit_CRU, mapleAllSub$Phenofit_HadA2, predictionsSub[,meanCols])	errorPredictions = predictionsSub[,SECols]	## plotting settings	meanZlims = c(0,1)	meanColors = colorRampPalette(c("#ffffff", "#bdc9e1", "#045a8d", "#33338d", "#cc99ff"), interpolate='spline', bias=1, space="rgb")(200)	meanTitles = c("A. Phenofit: Present", "B. Phenofit: HadA2", "C. Naive SDM: Present",  "D. Naive SDM: HadA2", "G. Integrated: Present", "H. Integrated: HadA2")	errorTitles = c("E. SDM: Present SE",  "F. SDM: HadA2 SE", "I. Integrated: Present SE", "J. Integrated: HadA2 SE")	meanScaleTitle = "Suitability"	errorZlims = range(errorPredictions)	errorColors = colorRampPalette(c("#ffffff", "#ffffb2", "#fecc5c", "#fd8d3c", "#e31a1c"), interpolate='spline', space="rgb", bias=1.3)(200)	errorScaleTitle = "Posterior Standard Error"	#
	# produce the plot#	pdf(file=pdfFileName, width=pdfWidth,height=pdfHeight)	quartz(width=pdfWidth,height=pdfHeight)	plotLayout = matrix(c(		1,2,11,11,		1,2,12,12,		3,4,7,8,		5,6,9,10),	  byrow=T, nrow=4)	layout(plotLayout, heights=c(0.5, 0.5, 1, 1))	par(mar=c(1,1,1,1))	for(i in 1:ncol(meanPredictions)) {		quilt.plot(longitude, latitude, meanPredictions[,i], col=meanColors, zlim=meanZlims, add.legend=F, xaxt='n', yaxt='n', useRaster=T)		plot(ocean, col="white", add=T)		plot(asRange[c(1,3,47,43),], border='red', col="#FF555500", add=T)		plot(grLakes, col="white", add=T)		mtext(meanTitles[i], adj=0, cex = titleCEX)	}	for(i in 1:ncol(errorPredictions)) {		quilt.plot(longitude, latitude, errorPredictions[,i], col=errorColors, zlim=errorZlims, add.legend=F, xaxt='n', yaxt='n', useRaster=T)		plot(ocean, col="white", add=T)		mtext(errorTitles[i], adj=0, cex = titleCEX)	}	## scale bars	par(mar=c(3,1,3,1))	image(x=seq(meanZlims[1],meanZlims[2],length.out=101), z=matrix(seq(meanZlims[1], meanZlims[2],length.out=100), 		nrow=100, ncol=1), zlim=meanZlims, col=meanColors, yaxt='n', xlab='', ylab='', useRaster=T)	mtext(meanScaleTitle, line=0.5, cex = titleCEX)	image(x=seq(errorZlims[1],errorZlims[2],length.out=101), z=matrix(seq(errorZlims[1], errorZlims[2],length.out=100), 		nrow=100, ncol=1), zlim=errorZlims, col=errorColors, yaxt='n', xlab='', ylab='', useRaster=T)	mtext(errorScaleTitle, line=0.5, cex = titleCEX)#	dev.off()}#
process_predictions = function(maple, naiveModel, intPredictions, intPosterior){##	builds an object containing the predictions of all models, both for all of the#	original data points (in result$all) and for the validation points (result$valid)##	maple: the same maple object saved in step 1#	naiveModel: the glm object representing the naive model#	intPredictions: a data frame of predictions (produced in step 4)#	intPosterior: the posterior samples from the integrated model, produced by step 3#	require(pROC)	# extract only the relevant climate variables	presClimate = maple$all[,which(colnames(maple$calib) %in% 		unique(naiveModel$variables$varNames))]	futClimate = maple$all[,which(substr(colnames(maple$calib),5, nchar(colnames(maple$calib)))		%in% unique(naiveModel$variables$varNames))]	validationClimate = maple$valid[,which(colnames(maple$calib) %in% 		unique(naiveModel$variables$varNames))]	colnames(futClimate) = colnames(presClimate)	# apply the transformations used in the calibration data to the projection datasets	presClimate = as.data.frame(sapply(names(presClimate), function(name) {		maple$transformations[[name]]$forward(presClimate[,name])}))	futClimate = as.data.frame(sapply(names(futClimate), function(name) {		maple$transformations[[name]]$forward(futClimate[,name])}))	validationClimate = as.data.frame(sapply(names(validationClimate), function(name) {		maple$transformations[[name]]$forward(validationClimate[,name])}))	# produce predictions for the naive model	naivePresPred = predict(naiveModel$model, newdata=presClimate, type='response', se.fit=TRUE)	naiveFutPred = predict(naiveModel$model, newdata=futClimate, type='response', se.fit=TRUE)	naiveValidPred = predict(naiveModel$model, newdata=validationClimate, type='response', se.fit=FALSE)	# wrap everything into a data frame	predictions = cbind(maple$all[,1:2], naivePresPred$fit, naivePresPred$se.fit, 		naiveFutPred$fit, naiveFutPred$se.fit, intPredictions)	colnames(predictions) = c("long", "lat", 		'naivePresent', 'naivePresentSE', 'naiveFuture', 'naiveFutureSE',		'intPresent', 'intPresentSE', 'intPresentLower', 'intPresentUpper',		'intFuture', 'intFutureSE', 'intFutureLower', 'intFutureUpper')	# validation	intValidPred = predict_mcmc(intPosterior, validationClimate)	validation = list(data = cbind(maple$valid[,1:5], naiveValidPred, intValidPred))	colnames(validation$data) = c('long', 'lat', 'presence', 'phenofitPres', 'phenofitFut', 'naive', 'integrated')	validation$naiveROC = roc(validation$data$presence, validation$data$naive)	validation$phenofitROC = roc(validation$data$presence, validation$data$phenofitPres)	validation$integratedROC = roc(validation$data$presence, validation$data$integrated)#
	return(list(all=predictions, valid=validation))}#
predict_mcmc = function(posteriorSample, newData) {##	Works like predict(), but for mcmc samples#	Returns the average prediction for each point in the new dataset#	#	posteriorSample: mcmc object; the posterior sample from which to produce predictions#	newData: data frame of predictors where predictions should be produced#	parPrefix = 2	parEnd = 1	#
	# predict the prob of presence for each point in newData	# assumes the FIRST parameter in posteriorSample is the intercept	predictedPrPresenceMean = mean(posteriorSample[,1])	currentCol = 2	while(currentCol <= ncol(posteriorSample)) {		ndColumn = which(colnames(newData) == substr(colnames(posteriorSample)[currentCol], parPrefix + 1, nchar(colnames(posteriorSample)[currentCol]) - parEnd))		exponent = as.integer(substr(colnames(posteriorSample)[currentCol], nchar(colnames(posteriorSample)[currentCol]), nchar(colnames(posteriorSample)[currentCol])))		predictedPrPresenceMean = predictedPrPresenceMean + mean(posteriorSample[,currentCol]) * newData[,ndColumn]^exponent				currentCol = currentCol + 1	}	predictedPrPresenceMean = inv_logit(predictedPrPresenceMean)		return(predictedPrPresenceMean)}#
inv_logit = function(x) {	inf.ind = which(x == Inf)		# negative infinity works normally, but Inf returns NaN	result = exp(x) / (1+exp(x))	result[inf.ind] = 1	return(result)}in.range = function(x, lims) x >= lims[1] & x <= lims[2]#
main()
# 5-make_figure.r# #   Copyright 2014 Matthew V Talluto, Isabelle Boulangeat, Dominique Gravel# #   This program is free software; you can redistribute it and/or modify#   it under the terms of the GNU General Public License as published by#   the Free Software Foundation; either version 3 of the License, or (at#   your option) any later version.#   #   This program is distributed in the hope that it will be useful, but#   WITHOUT ANY WARRANTY; without even the implied warranty of#   MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU#   General Public License for more details.# #   You should have received a copy of the GNU General Public License#   along with this program; if not, write to the Free Software#   Foundation, Inc., 51 Franklin Street, Fifth Floor, Boston, MA 02110-1301, USA.##### produce the figure for the second example###
main = function(){	require(fields)	require(rgdal)	require(coda)#
	load("dat/naive_model.rdata")	intPredictions = read.csv("results/integratedStats.csv")	load("results/integratedModel.rdata")#
	predictions = process_predictions(maple, naiveModel, intPredictions, integratedModel)#	ocean = readOGR(dsn="dat/ne_10m_ocean", layer="ne_10m_ocean")#	lakes = readOGR(dsn="dat/ne_10m_lakes", layer="ne_10m_lakes")	ocean = readOGR(dsn="dat/ne_50m_ocean", layer="ne_50m_ocean")	lakes = readOGR(dsn="dat/ne_50m_lakes", layer="ne_50m_lakes")	mapleRange = readOGR(dsn="dat/acersacr", layer="acersacr")	# grab specific lakes	lkNames = c("Lake Huron", "Lake Michigan", "Lake Superior", "Lake Ontario", "Lake Erie", "Lake St. Clair")	grLakes = lakes[which(lakes$name %in% lkNames),]	pdfFileName = "ex2.pdf"	pdfWidth = 7.5	pdfHeight = 6	titleCEX = 0.7#
	# which columns to loop thru for mean and errors	meanCols = c(3,5,7,11)	SECols = meanCols + 1	## pick the data to display	latLimits = c(27,65)	longLimits = c(-105, -55)	predictionsSub = subset(predictions$all, in.range(lat, latLimits) & in.range(long, longLimits))	mapleAllSub = subset(maple$all, in.range(lat, latLimits) & in.range(long, longLimits))	latitude = predictionsSub[,2]	longitude = predictionsSub[,1]	meanPredictions = cbind(mapleAllSub$Phenofit_CRU, mapleAllSub$Phenofit_HadA2, predictionsSub[,meanCols])	errorPredictions = predictionsSub[,SECols]	## plotting settings	meanZlims = c(0,1)	meanColors = colorRampPalette(c("#ffffff", "#bdc9e1", "#045a8d", "#33338d", "#cc99ff"), interpolate='spline', bias=1, space="rgb")(200)	meanTitles = c("A. Phenofit: Present", "B. Phenofit: HadA2", "C. Naive SDM: Present",  "D. Naive SDM: HadA2", "G. Integrated: Present", "H. Integrated: HadA2")	errorTitles = c("E. SDM: Present SE",  "F. SDM: HadA2 SE", "I. Integrated: Present SE", "J. Integrated: HadA2 SE")	meanScaleTitle = "Suitability"	errorZlims = range(errorPredictions)	errorColors = colorRampPalette(c("#ffffff", "#ffffb2", "#fecc5c", "#fd8d3c", "#e31a1c"), interpolate='spline', space="rgb", bias=1.3)(200)	errorScaleTitle = "Posterior Standard Error"	#
	# produce the plot#	pdf(file=pdfFileName, width=pdfWidth,height=pdfHeight)	quartz(width=pdfWidth,height=pdfHeight)	plotLayout = matrix(c(		1,2,11,11,		1,2,12,12,		3,4,7,8,		5,6,9,10),	  byrow=T, nrow=4)	layout(plotLayout, heights=c(0.5, 0.5, 1, 1))	par(mar=c(1,1,1,1))	for(i in 1:ncol(meanPredictions)) {		quilt.plot(longitude, latitude, meanPredictions[,i], col=meanColors, zlim=meanZlims, add.legend=F, xaxt='n', yaxt='n', useRaster=T)		plot(ocean, col="white", add=T)		plot(asRange[c(1,3,47,43),], border='#FF333399', col="#FF555500", add=T)		plot(grLakes, col="white", add=T)		mtext(meanTitles[i], adj=0, cex = titleCEX)	}	for(i in 1:ncol(errorPredictions)) {		quilt.plot(longitude, latitude, errorPredictions[,i], col=errorColors, zlim=errorZlims, add.legend=F, xaxt='n', yaxt='n', useRaster=T)		plot(ocean, col="white", add=T)		mtext(errorTitles[i], adj=0, cex = titleCEX)	}	## scale bars	par(mar=c(3,1,3,1))	image(x=seq(meanZlims[1],meanZlims[2],length.out=101), z=matrix(seq(meanZlims[1], meanZlims[2],length.out=100), 		nrow=100, ncol=1), zlim=meanZlims, col=meanColors, yaxt='n', xlab='', ylab='', useRaster=T)	mtext(meanScaleTitle, line=0.5, cex = titleCEX)	image(x=seq(errorZlims[1],errorZlims[2],length.out=101), z=matrix(seq(errorZlims[1], errorZlims[2],length.out=100), 		nrow=100, ncol=1), zlim=errorZlims, col=errorColors, yaxt='n', xlab='', ylab='', useRaster=T)	mtext(errorScaleTitle, line=0.5, cex = titleCEX)#	dev.off()}#
process_predictions = function(maple, naiveModel, intPredictions, intPosterior){##	builds an object containing the predictions of all models, both for all of the#	original data points (in result$all) and for the validation points (result$valid)##	maple: the same maple object saved in step 1#	naiveModel: the glm object representing the naive model#	intPredictions: a data frame of predictions (produced in step 4)#	intPosterior: the posterior samples from the integrated model, produced by step 3#	require(pROC)	# extract only the relevant climate variables	presClimate = maple$all[,which(colnames(maple$calib) %in% 		unique(naiveModel$variables$varNames))]	futClimate = maple$all[,which(substr(colnames(maple$calib),5, nchar(colnames(maple$calib)))		%in% unique(naiveModel$variables$varNames))]	validationClimate = maple$valid[,which(colnames(maple$calib) %in% 		unique(naiveModel$variables$varNames))]	colnames(futClimate) = colnames(presClimate)	# apply the transformations used in the calibration data to the projection datasets	presClimate = as.data.frame(sapply(names(presClimate), function(name) {		maple$transformations[[name]]$forward(presClimate[,name])}))	futClimate = as.data.frame(sapply(names(futClimate), function(name) {		maple$transformations[[name]]$forward(futClimate[,name])}))	validationClimate = as.data.frame(sapply(names(validationClimate), function(name) {		maple$transformations[[name]]$forward(validationClimate[,name])}))	# produce predictions for the naive model	naivePresPred = predict(naiveModel$model, newdata=presClimate, type='response', se.fit=TRUE)	naiveFutPred = predict(naiveModel$model, newdata=futClimate, type='response', se.fit=TRUE)	naiveValidPred = predict(naiveModel$model, newdata=validationClimate, type='response', se.fit=FALSE)	# wrap everything into a data frame	predictions = cbind(maple$all[,1:2], naivePresPred$fit, naivePresPred$se.fit, 		naiveFutPred$fit, naiveFutPred$se.fit, intPredictions)	colnames(predictions) = c("long", "lat", 		'naivePresent', 'naivePresentSE', 'naiveFuture', 'naiveFutureSE',		'intPresent', 'intPresentSE', 'intPresentLower', 'intPresentUpper',		'intFuture', 'intFutureSE', 'intFutureLower', 'intFutureUpper')	# validation	intValidPred = predict_mcmc(intPosterior, validationClimate)	validation = list(data = cbind(maple$valid[,1:5], naiveValidPred, intValidPred))	colnames(validation$data) = c('long', 'lat', 'presence', 'phenofitPres', 'phenofitFut', 'naive', 'integrated')	validation$naiveROC = roc(validation$data$presence, validation$data$naive)	validation$phenofitROC = roc(validation$data$presence, validation$data$phenofitPres)	validation$integratedROC = roc(validation$data$presence, validation$data$integrated)#
	return(list(all=predictions, valid=validation))}#
predict_mcmc = function(posteriorSample, newData) {##	Works like predict(), but for mcmc samples#	Returns the average prediction for each point in the new dataset#	#	posteriorSample: mcmc object; the posterior sample from which to produce predictions#	newData: data frame of predictors where predictions should be produced#	parPrefix = 2	parEnd = 1	#
	# predict the prob of presence for each point in newData	# assumes the FIRST parameter in posteriorSample is the intercept	predictedPrPresenceMean = mean(posteriorSample[,1])	currentCol = 2	while(currentCol <= ncol(posteriorSample)) {		ndColumn = which(colnames(newData) == substr(colnames(posteriorSample)[currentCol], parPrefix + 1, nchar(colnames(posteriorSample)[currentCol]) - parEnd))		exponent = as.integer(substr(colnames(posteriorSample)[currentCol], nchar(colnames(posteriorSample)[currentCol]), nchar(colnames(posteriorSample)[currentCol])))		predictedPrPresenceMean = predictedPrPresenceMean + mean(posteriorSample[,currentCol]) * newData[,ndColumn]^exponent				currentCol = currentCol + 1	}	predictedPrPresenceMean = inv_logit(predictedPrPresenceMean)		return(predictedPrPresenceMean)}#
inv_logit = function(x) {	inf.ind = which(x == Inf)		# negative infinity works normally, but Inf returns NaN	result = exp(x) / (1+exp(x))	result[inf.ind] = 1	return(result)}in.range = function(x, lims) x >= lims[1] & x <= lims[2]#
main()
lakes = readOGR(dsn="dat/ne_50m_lakes", layer="ne_50m_lakes")
lkNames = c("Lake Huron", "Lake Michigan", "Lake Superior", "Lake Ontario", "Lake Erie", "Lake St. Clair")
which(lakes$name %in% lkNames)
lakes$name[25:30,]
lakes$name[25:30]
grep("Erie", lakes$name)
lakes$name[grep("Erie", lakes$name)]
lakes$name[grep("Ontario", lakes$name)]
nms = c('Ontario', 'Erie')
grep(nms, lakes$name)
sapply(nms, grep, lakes$name
)
lkNames = c("Huron", "Michigan", "Superior", "Ontario", "Erie", "St. Clair")
sapply(lkNames, grep, lakes$name)
lakes$name(sapply(lkNames, grep, lakes$name))
as.integer(sapply(lkNames, grep, lakes$name))
grLakes = lakes[as.integer(sapply(lkNames, grep, lakes$name)),]
# 5-make_figure.r# #   Copyright 2014 Matthew V Talluto, Isabelle Boulangeat, Dominique Gravel# #   This program is free software; you can redistribute it and/or modify#   it under the terms of the GNU General Public License as published by#   the Free Software Foundation; either version 3 of the License, or (at#   your option) any later version.#   #   This program is distributed in the hope that it will be useful, but#   WITHOUT ANY WARRANTY; without even the implied warranty of#   MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU#   General Public License for more details.# #   You should have received a copy of the GNU General Public License#   along with this program; if not, write to the Free Software#   Foundation, Inc., 51 Franklin Street, Fifth Floor, Boston, MA 02110-1301, USA.##### produce the figure for the second example###
main = function(){	require(fields)	require(rgdal)	require(coda)#
	load("dat/naive_model.rdata")	intPredictions = read.csv("results/integratedStats.csv")	load("results/integratedModel.rdata")#
	predictions = process_predictions(maple, naiveModel, intPredictions, integratedModel)#	ocean = readOGR(dsn="dat/ne_10m_ocean", layer="ne_10m_ocean")#	lakes = readOGR(dsn="dat/ne_10m_lakes", layer="ne_10m_lakes")	ocean = readOGR(dsn="dat/ne_50m_ocean", layer="ne_50m_ocean")	lakes = readOGR(dsn="dat/ne_50m_lakes", layer="ne_50m_lakes")	mapleRange = readOGR(dsn="dat/acersacr", layer="acersacr")	# grab specific lakes	lkNames = c("Huron", "Michigan", "Superior", "Ontario", "Erie", "St. Clair")	grLakes = lakes[as.integer(sapply(lkNames, grep, lakes$name)),]	pdfFileName = "ex2.pdf"	pdfWidth = 7.5	pdfHeight = 6	titleCEX = 0.7#
	# which columns to loop thru for mean and errors	meanCols = c(3,5,7,11)	SECols = meanCols + 1	## pick the data to display	latLimits = c(27,65)	longLimits = c(-105, -55)	predictionsSub = subset(predictions$all, in.range(lat, latLimits) & in.range(long, longLimits))	mapleAllSub = subset(maple$all, in.range(lat, latLimits) & in.range(long, longLimits))	latitude = predictionsSub[,2]	longitude = predictionsSub[,1]	meanPredictions = cbind(mapleAllSub$Phenofit_CRU, mapleAllSub$Phenofit_HadA2, predictionsSub[,meanCols])	errorPredictions = predictionsSub[,SECols]	## plotting settings	meanZlims = c(0,1)	meanColors = colorRampPalette(c("#ffffff", "#bdc9e1", "#045a8d", "#33338d", "#cc99ff"), interpolate='spline', bias=1, space="rgb")(200)	meanTitles = c("A. Phenofit: Present", "B. Phenofit: HadA2", "C. Naive SDM: Present",  "D. Naive SDM: HadA2", "G. Integrated: Present", "H. Integrated: HadA2")	errorTitles = c("E. SDM: Present SE",  "F. SDM: HadA2 SE", "I. Integrated: Present SE", "J. Integrated: HadA2 SE")	meanScaleTitle = "Suitability"	errorZlims = range(errorPredictions)	errorColors = colorRampPalette(c("#ffffff", "#ffffb2", "#fecc5c", "#fd8d3c", "#e31a1c"), interpolate='spline', space="rgb", bias=1.3)(200)	errorScaleTitle = "Posterior Standard Error"	#
	# produce the plot#	pdf(file=pdfFileName, width=pdfWidth,height=pdfHeight)	quartz(width=pdfWidth,height=pdfHeight)	plotLayout = matrix(c(		1,2,11,11,		1,2,12,12,		3,4,7,8,		5,6,9,10),	  byrow=T, nrow=4)	layout(plotLayout, heights=c(0.5, 0.5, 1, 1))	par(mar=c(1,1,1,1))	for(i in 1:ncol(meanPredictions)) {		quilt.plot(longitude, latitude, meanPredictions[,i], col=meanColors, zlim=meanZlims, add.legend=F, xaxt='n', yaxt='n', useRaster=T)		plot(ocean, col="white", add=T)		plot(asRange[c(1,3,47,43),], border='#FF333399', col="#FF555500", add=T)		plot(grLakes, col="white", add=T)		mtext(meanTitles[i], adj=0, cex = titleCEX)	}	for(i in 1:ncol(errorPredictions)) {		quilt.plot(longitude, latitude, errorPredictions[,i], col=errorColors, zlim=errorZlims, add.legend=F, xaxt='n', yaxt='n', useRaster=T)		plot(ocean, col="white", add=T)		mtext(errorTitles[i], adj=0, cex = titleCEX)	}	## scale bars	par(mar=c(3,1,3,1))	image(x=seq(meanZlims[1],meanZlims[2],length.out=101), z=matrix(seq(meanZlims[1], meanZlims[2],length.out=100), 		nrow=100, ncol=1), zlim=meanZlims, col=meanColors, yaxt='n', xlab='', ylab='', useRaster=T)	mtext(meanScaleTitle, line=0.5, cex = titleCEX)	image(x=seq(errorZlims[1],errorZlims[2],length.out=101), z=matrix(seq(errorZlims[1], errorZlims[2],length.out=100), 		nrow=100, ncol=1), zlim=errorZlims, col=errorColors, yaxt='n', xlab='', ylab='', useRaster=T)	mtext(errorScaleTitle, line=0.5, cex = titleCEX)#	dev.off()}#
process_predictions = function(maple, naiveModel, intPredictions, intPosterior){##	builds an object containing the predictions of all models, both for all of the#	original data points (in result$all) and for the validation points (result$valid)##	maple: the same maple object saved in step 1#	naiveModel: the glm object representing the naive model#	intPredictions: a data frame of predictions (produced in step 4)#	intPosterior: the posterior samples from the integrated model, produced by step 3#	require(pROC)	# extract only the relevant climate variables	presClimate = maple$all[,which(colnames(maple$calib) %in% 		unique(naiveModel$variables$varNames))]	futClimate = maple$all[,which(substr(colnames(maple$calib),5, nchar(colnames(maple$calib)))		%in% unique(naiveModel$variables$varNames))]	validationClimate = maple$valid[,which(colnames(maple$calib) %in% 		unique(naiveModel$variables$varNames))]	colnames(futClimate) = colnames(presClimate)	# apply the transformations used in the calibration data to the projection datasets	presClimate = as.data.frame(sapply(names(presClimate), function(name) {		maple$transformations[[name]]$forward(presClimate[,name])}))	futClimate = as.data.frame(sapply(names(futClimate), function(name) {		maple$transformations[[name]]$forward(futClimate[,name])}))	validationClimate = as.data.frame(sapply(names(validationClimate), function(name) {		maple$transformations[[name]]$forward(validationClimate[,name])}))	# produce predictions for the naive model	naivePresPred = predict(naiveModel$model, newdata=presClimate, type='response', se.fit=TRUE)	naiveFutPred = predict(naiveModel$model, newdata=futClimate, type='response', se.fit=TRUE)	naiveValidPred = predict(naiveModel$model, newdata=validationClimate, type='response', se.fit=FALSE)	# wrap everything into a data frame	predictions = cbind(maple$all[,1:2], naivePresPred$fit, naivePresPred$se.fit, 		naiveFutPred$fit, naiveFutPred$se.fit, intPredictions)	colnames(predictions) = c("long", "lat", 		'naivePresent', 'naivePresentSE', 'naiveFuture', 'naiveFutureSE',		'intPresent', 'intPresentSE', 'intPresentLower', 'intPresentUpper',		'intFuture', 'intFutureSE', 'intFutureLower', 'intFutureUpper')	# validation	intValidPred = predict_mcmc(intPosterior, validationClimate)	validation = list(data = cbind(maple$valid[,1:5], naiveValidPred, intValidPred))	colnames(validation$data) = c('long', 'lat', 'presence', 'phenofitPres', 'phenofitFut', 'naive', 'integrated')	validation$naiveROC = roc(validation$data$presence, validation$data$naive)	validation$phenofitROC = roc(validation$data$presence, validation$data$phenofitPres)	validation$integratedROC = roc(validation$data$presence, validation$data$integrated)#
	return(list(all=predictions, valid=validation))}#
predict_mcmc = function(posteriorSample, newData) {##	Works like predict(), but for mcmc samples#	Returns the average prediction for each point in the new dataset#	#	posteriorSample: mcmc object; the posterior sample from which to produce predictions#	newData: data frame of predictors where predictions should be produced#	parPrefix = 2	parEnd = 1	#
	# predict the prob of presence for each point in newData	# assumes the FIRST parameter in posteriorSample is the intercept	predictedPrPresenceMean = mean(posteriorSample[,1])	currentCol = 2	while(currentCol <= ncol(posteriorSample)) {		ndColumn = which(colnames(newData) == substr(colnames(posteriorSample)[currentCol], parPrefix + 1, nchar(colnames(posteriorSample)[currentCol]) - parEnd))		exponent = as.integer(substr(colnames(posteriorSample)[currentCol], nchar(colnames(posteriorSample)[currentCol]), nchar(colnames(posteriorSample)[currentCol])))		predictedPrPresenceMean = predictedPrPresenceMean + mean(posteriorSample[,currentCol]) * newData[,ndColumn]^exponent				currentCol = currentCol + 1	}	predictedPrPresenceMean = inv_logit(predictedPrPresenceMean)		return(predictedPrPresenceMean)}#
inv_logit = function(x) {	inf.ind = which(x == Inf)		# negative infinity works normally, but Inf returns NaN	result = exp(x) / (1+exp(x))	result[inf.ind] = 1	return(result)}in.range = function(x, lims) x >= lims[1] & x <= lims[2]#
main()
load("dat/naive_model.rdata")	intPredictions = read.csv("results/integratedStats.csv")	load("results/integratedModel.rdata")#
	predictions = process_predictions(maple, naiveModel, intPredictions, integratedModel)	ocean = readOGR(dsn="dat/ne_50m_ocean", layer="ne_50m_ocean")	lakes = readOGR(dsn="dat/ne_50m_lakes", layer="ne_50m_lakes")	mapleRange = readOGR(dsn="dat/acersacr", layer="acersacr")	# grab specific lakes	lkNames = c("Huron", "Michigan", "Superior", "Ontario", "Erie", "St. Clair")	grLakes = lakes[as.integer(sapply(lkNames, grep, lakes$name)),]	pdfFileName = "ex2.pdf"	pdfWidth = 7.5	pdfHeight = 6	titleCEX = 0.7#
	# which columns to loop thru for mean and errors	meanCols = c(3,5,7,11)	SECols = meanCols + 1
latLimits = c(27,65)	longLimits = c(-105, -55)
predictionsSub = subset(predictions$all, in.range(lat, latLimits) & in.range(long, longLimits))	mapleAllSub = subset(maple$all, in.range(lat, latLimits) & in.range(long, longLimits))	latitude = predictionsSub[,2]	longitude = predictionsSub[,1]
# 5-make_figure.r# #   Copyright 2014 Matthew V Talluto, Isabelle Boulangeat, Dominique Gravel# #   This program is free software; you can redistribute it and/or modify#   it under the terms of the GNU General Public License as published by#   the Free Software Foundation; either version 3 of the License, or (at#   your option) any later version.#   #   This program is distributed in the hope that it will be useful, but#   WITHOUT ANY WARRANTY; without even the implied warranty of#   MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU#   General Public License for more details.# #   You should have received a copy of the GNU General Public License#   along with this program; if not, write to the Free Software#   Foundation, Inc., 51 Franklin Street, Fifth Floor, Boston, MA 02110-1301, USA.##### produce the figure for the second example###
main = function(){	require(fields)	require(rgdal)	require(coda)#
	load("dat/naive_model.rdata")	intPredictions = read.csv("results/integratedStats.csv")	load("results/integratedModel.rdata")#
	predictions = process_predictions(maple, naiveModel, intPredictions, integratedModel)	ocean = readOGR(dsn="dat/ne_50m_ocean", layer="ne_50m_ocean")	lakes = readOGR(dsn="dat/ne_50m_lakes", layer="ne_50m_lakes")	mapleRange = readOGR(dsn="dat/acersacr", layer="acersacr")	# grab specific lakes	lkNames = c("Huron", "Michigan", "Superior", "Ontario", "Erie", "St. Clair")	grLakes = lakes[as.integer(sapply(lkNames, grep, lakes$name)),]	pdfFileName = "ex2.pdf"	pdfWidth = 7.5	pdfHeight = 6	titleCEX = 0.7#
	# which columns to loop thru for mean and errors	meanCols = c(5,11)	SECols = meanCols + 1	## pick the data to display	latLimits = c(27,65)	longLimits = c(-105, -55)	predictionsSub = subset(predictions$all, in.range(lat, latLimits) & in.range(long, longLimits))	mapleAllSub = subset(maple$all, in.range(lat, latLimits) & in.range(long, longLimits))	latitude = predictionsSub[,2]	longitude = predictionsSub[,1]	meanPredictions = cbind(mapleAllSub$Phenofit_HadA2, predictionsSub[,meanCols])	errorPredictions = predictionsSub[,SECols]	## plotting settings	meanZlims = c(0,1)	meanColors = colorRampPalette(c("#ffffff", "#bdc9e1", "#045a8d", "#33338d", "#cc99ff"), interpolate='spline', bias=1, space="rgb")(200)	meanTitles = c("A. Phenofit", "B. Naive SDM", "D. Integrated")	errorTitles = c("C. Naive SDM SE", "E. Integrated SE")	meanScaleTitle = "Suitability"	errorZlims = range(errorPredictions)	errorColors = colorRampPalette(c("#ffffff", "#ffffb2", "#fecc5c", "#fd8d3c", "#e31a1c"), interpolate='spline', space="rgb", bias=1.3)(200)	errorScaleTitle = "Posterior Standard Error"	#
	# produce the plot#	pdf(file=pdfFileName, width=pdfWidth,height=pdfHeight)	quartz(width=pdfWidth,height=pdfHeight)	plotLayout = matrix(c(		1,2,3,		6,4,5,		6,4,5),	  byrow=T, nrow=3)	layout(plotLayout)	par(mar=c(1,1,1,1))	for(i in 1:ncol(meanPredictions)) {		quilt.plot(longitude, latitude, meanPredictions[,i], col=meanColors, zlim=meanZlims, add.legend=F, xaxt='n', yaxt='n', useRaster=T)		plot(ocean, col="white", add=T)		plot(asRange[c(1,3,47,43),], border='#FF333399', col="#FF555500", add=T)		plot(grLakes, col="white", add=T)		mtext(meanTitles[i], adj=0, cex = titleCEX)	}	for(i in 1:ncol(errorPredictions)) {		quilt.plot(longitude, latitude, errorPredictions[,i], col=errorColors, zlim=errorZlims, add.legend=F, xaxt='n', yaxt='n', useRaster=T)		plot(ocean, col="white", add=T)		mtext(errorTitles[i], adj=0, cex = titleCEX)	}	## scale bars	par(mar=c(3,1,3,1))	image(x=seq(meanZlims[1],meanZlims[2],length.out=101), z=matrix(seq(meanZlims[1], meanZlims[2],length.out=100), 		nrow=100, ncol=1), zlim=meanZlims, col=meanColors, yaxt='n', xlab='', ylab='', useRaster=T)	mtext(meanScaleTitle, line=0.5, cex = titleCEX)	image(x=seq(errorZlims[1],errorZlims[2],length.out=101), z=matrix(seq(errorZlims[1], errorZlims[2],length.out=100), 		nrow=100, ncol=1), zlim=errorZlims, col=errorColors, yaxt='n', xlab='', ylab='', useRaster=T)	mtext(errorScaleTitle, line=0.5, cex = titleCEX)#	dev.off()}#
process_predictions = function(maple, naiveModel, intPredictions, intPosterior){##	builds an object containing the predictions of all models, both for all of the#	original data points (in result$all) and for the validation points (result$valid)##	maple: the same maple object saved in step 1#	naiveModel: the glm object representing the naive model#	intPredictions: a data frame of predictions (produced in step 4)#	intPosterior: the posterior samples from the integrated model, produced by step 3#	require(pROC)	# extract only the relevant climate variables	presClimate = maple$all[,which(colnames(maple$calib) %in% 		unique(naiveModel$variables$varNames))]	futClimate = maple$all[,which(substr(colnames(maple$calib),5, nchar(colnames(maple$calib)))		%in% unique(naiveModel$variables$varNames))]	validationClimate = maple$valid[,which(colnames(maple$calib) %in% 		unique(naiveModel$variables$varNames))]	colnames(futClimate) = colnames(presClimate)	# apply the transformations used in the calibration data to the projection datasets	presClimate = as.data.frame(sapply(names(presClimate), function(name) {		maple$transformations[[name]]$forward(presClimate[,name])}))	futClimate = as.data.frame(sapply(names(futClimate), function(name) {		maple$transformations[[name]]$forward(futClimate[,name])}))	validationClimate = as.data.frame(sapply(names(validationClimate), function(name) {		maple$transformations[[name]]$forward(validationClimate[,name])}))	# produce predictions for the naive model	naivePresPred = predict(naiveModel$model, newdata=presClimate, type='response', se.fit=TRUE)	naiveFutPred = predict(naiveModel$model, newdata=futClimate, type='response', se.fit=TRUE)	naiveValidPred = predict(naiveModel$model, newdata=validationClimate, type='response', se.fit=FALSE)	# wrap everything into a data frame	predictions = cbind(maple$all[,1:2], naivePresPred$fit, naivePresPred$se.fit, 		naiveFutPred$fit, naiveFutPred$se.fit, intPredictions)	colnames(predictions) = c("long", "lat", 		'naivePresent', 'naivePresentSE', 'naiveFuture', 'naiveFutureSE',		'intPresent', 'intPresentSE', 'intPresentLower', 'intPresentUpper',		'intFuture', 'intFutureSE', 'intFutureLower', 'intFutureUpper')	# validation	intValidPred = predict_mcmc(intPosterior, validationClimate)	validation = list(data = cbind(maple$valid[,1:5], naiveValidPred, intValidPred))	colnames(validation$data) = c('long', 'lat', 'presence', 'phenofitPres', 'phenofitFut', 'naive', 'integrated')	validation$naiveROC = roc(validation$data$presence, validation$data$naive)	validation$phenofitROC = roc(validation$data$presence, validation$data$phenofitPres)	validation$integratedROC = roc(validation$data$presence, validation$data$integrated)#
	return(list(all=predictions, valid=validation))}#
predict_mcmc = function(posteriorSample, newData) {##	Works like predict(), but for mcmc samples#	Returns the average prediction for each point in the new dataset#	#	posteriorSample: mcmc object; the posterior sample from which to produce predictions#	newData: data frame of predictors where predictions should be produced#	parPrefix = 2	parEnd = 1	#
	# predict the prob of presence for each point in newData	# assumes the FIRST parameter in posteriorSample is the intercept	predictedPrPresenceMean = mean(posteriorSample[,1])	currentCol = 2	while(currentCol <= ncol(posteriorSample)) {		ndColumn = which(colnames(newData) == substr(colnames(posteriorSample)[currentCol], parPrefix + 1, nchar(colnames(posteriorSample)[currentCol]) - parEnd))		exponent = as.integer(substr(colnames(posteriorSample)[currentCol], nchar(colnames(posteriorSample)[currentCol]), nchar(colnames(posteriorSample)[currentCol])))		predictedPrPresenceMean = predictedPrPresenceMean + mean(posteriorSample[,currentCol]) * newData[,ndColumn]^exponent				currentCol = currentCol + 1	}	predictedPrPresenceMean = inv_logit(predictedPrPresenceMean)		return(predictedPrPresenceMean)}#
inv_logit = function(x) {	inf.ind = which(x == Inf)		# negative infinity works normally, but Inf returns NaN	result = exp(x) / (1+exp(x))	result[inf.ind] = 1	return(result)}in.range = function(x, lims) x >= lims[1] & x <= lims[2]#
main()
# 5-make_figure.r# #   Copyright 2014 Matthew V Talluto, Isabelle Boulangeat, Dominique Gravel# #   This program is free software; you can redistribute it and/or modify#   it under the terms of the GNU General Public License as published by#   the Free Software Foundation; either version 3 of the License, or (at#   your option) any later version.#   #   This program is distributed in the hope that it will be useful, but#   WITHOUT ANY WARRANTY; without even the implied warranty of#   MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU#   General Public License for more details.# #   You should have received a copy of the GNU General Public License#   along with this program; if not, write to the Free Software#   Foundation, Inc., 51 Franklin Street, Fifth Floor, Boston, MA 02110-1301, USA.##### produce the figure for the second example###
main = function(){	require(fields)	require(rgdal)	require(coda)#
	load("dat/naive_model.rdata")	intPredictions = read.csv("results/integratedStats.csv")	load("results/integratedModel.rdata")#
	predictions = process_predictions(maple, naiveModel, intPredictions, integratedModel)	ocean = readOGR(dsn="dat/ne_50m_ocean", layer="ne_50m_ocean")	lakes = readOGR(dsn="dat/ne_50m_lakes", layer="ne_50m_lakes")	mapleRange = readOGR(dsn="dat/acersacr", layer="acersacr")	# grab specific lakes	lkNames = c("Huron", "Michigan", "Superior", "Ontario", "Erie", "St. Clair")	grLakes = lakes[as.integer(sapply(lkNames, grep, lakes$name)),]	pdfFileName = "ex2.pdf"	pdfWidth = 7.5	pdfHeight = 6	titleCEX = 0.7#
	# which columns to loop thru for mean and errors	meanCols = c(5,11)	SECols = meanCols + 1	## pick the data to display	latLimits = c(27,65)	longLimits = c(-105, -55)	predictionsSub = subset(predictions$all, in.range(lat, latLimits) & in.range(long, longLimits))	mapleAllSub = subset(maple$all, in.range(lat, latLimits) & in.range(long, longLimits))	latitude = predictionsSub[,2]	longitude = predictionsSub[,1]	meanPredictions = cbind(mapleAllSub$Phenofit_HadA2, predictionsSub[,meanCols])	errorPredictions = predictionsSub[,SECols]	## plotting settings	meanZlims = c(0,1)	meanColors = colorRampPalette(c("#ffffff", "#bdc9e1", "#045a8d", "#33338d", "#cc99ff"), interpolate='spline', bias=1, space="rgb")(200)	meanTitles = c("A. Phenofit", "B. Naive SDM", "D. Integrated")	errorTitles = c("C. Naive SDM SE", "E. Integrated SE")	meanScaleTitle = "Suitability"	errorZlims = range(errorPredictions)	errorColors = colorRampPalette(c("#ffffff", "#ffffb2", "#fecc5c", "#fd8d3c", "#e31a1c"), interpolate='spline', space="rgb", bias=1.3)(200)	errorScaleTitle = "Posterior Standard Error"	#
	# produce the plot#	pdf(file=pdfFileName, width=pdfWidth,height=pdfHeight)	quartz(width=pdfWidth,height=pdfHeight)	plotLayout = matrix(c(		1,2,3,		6,4,5,		7,4,5),	  byrow=T, nrow=3)	layout(plotLayout, heights=c(1, 0.5, 0.5))	par(mar=c(1,1,1,1))	for(i in 1:ncol(meanPredictions)) {		quilt.plot(longitude, latitude, meanPredictions[,i], col=meanColors, zlim=meanZlims, add.legend=F, xaxt='n', yaxt='n', useRaster=T)		plot(ocean, col="white", add=T)		plot(asRange[c(1,3,47,43),], border='#FF333399', col="#FF555500", add=T)		plot(grLakes, col="white", add=T)		mtext(meanTitles[i], adj=0, cex = titleCEX)	}	for(i in 1:ncol(errorPredictions)) {		quilt.plot(longitude, latitude, errorPredictions[,i], col=errorColors, zlim=errorZlims, add.legend=F, xaxt='n', yaxt='n', useRaster=T)		plot(ocean, col="white", add=T)		plot(asRange[c(1,3,47,43),], border='#FF333399', col="#FF555500", add=T)		plot(grLakes, col="white", add=T)		mtext(errorTitles[i], adj=0, cex = titleCEX)	}	## scale bars	par(mar=c(3,1,3,1))	image(x=seq(meanZlims[1],meanZlims[2],length.out=101), z=matrix(seq(meanZlims[1], meanZlims[2],length.out=100), 		nrow=100, ncol=1), zlim=meanZlims, col=meanColors, yaxt='n', xlab='', ylab='', useRaster=T)	mtext(meanScaleTitle, line=0.5, cex = titleCEX)	image(x=seq(errorZlims[1],errorZlims[2],length.out=101), z=matrix(seq(errorZlims[1], errorZlims[2],length.out=100), 		nrow=100, ncol=1), zlim=errorZlims, col=errorColors, yaxt='n', xlab='', ylab='', useRaster=T)	mtext(errorScaleTitle, line=0.5, cex = titleCEX)#	dev.off()}#
process_predictions = function(maple, naiveModel, intPredictions, intPosterior){##	builds an object containing the predictions of all models, both for all of the#	original data points (in result$all) and for the validation points (result$valid)##	maple: the same maple object saved in step 1#	naiveModel: the glm object representing the naive model#	intPredictions: a data frame of predictions (produced in step 4)#	intPosterior: the posterior samples from the integrated model, produced by step 3#	require(pROC)	# extract only the relevant climate variables	presClimate = maple$all[,which(colnames(maple$calib) %in% 		unique(naiveModel$variables$varNames))]	futClimate = maple$all[,which(substr(colnames(maple$calib),5, nchar(colnames(maple$calib)))		%in% unique(naiveModel$variables$varNames))]	validationClimate = maple$valid[,which(colnames(maple$calib) %in% 		unique(naiveModel$variables$varNames))]	colnames(futClimate) = colnames(presClimate)	# apply the transformations used in the calibration data to the projection datasets	presClimate = as.data.frame(sapply(names(presClimate), function(name) {		maple$transformations[[name]]$forward(presClimate[,name])}))	futClimate = as.data.frame(sapply(names(futClimate), function(name) {		maple$transformations[[name]]$forward(futClimate[,name])}))	validationClimate = as.data.frame(sapply(names(validationClimate), function(name) {		maple$transformations[[name]]$forward(validationClimate[,name])}))	# produce predictions for the naive model	naivePresPred = predict(naiveModel$model, newdata=presClimate, type='response', se.fit=TRUE)	naiveFutPred = predict(naiveModel$model, newdata=futClimate, type='response', se.fit=TRUE)	naiveValidPred = predict(naiveModel$model, newdata=validationClimate, type='response', se.fit=FALSE)	# wrap everything into a data frame	predictions = cbind(maple$all[,1:2], naivePresPred$fit, naivePresPred$se.fit, 		naiveFutPred$fit, naiveFutPred$se.fit, intPredictions)	colnames(predictions) = c("long", "lat", 		'naivePresent', 'naivePresentSE', 'naiveFuture', 'naiveFutureSE',		'intPresent', 'intPresentSE', 'intPresentLower', 'intPresentUpper',		'intFuture', 'intFutureSE', 'intFutureLower', 'intFutureUpper')	# validation	intValidPred = predict_mcmc(intPosterior, validationClimate)	validation = list(data = cbind(maple$valid[,1:5], naiveValidPred, intValidPred))	colnames(validation$data) = c('long', 'lat', 'presence', 'phenofitPres', 'phenofitFut', 'naive', 'integrated')	validation$naiveROC = roc(validation$data$presence, validation$data$naive)	validation$phenofitROC = roc(validation$data$presence, validation$data$phenofitPres)	validation$integratedROC = roc(validation$data$presence, validation$data$integrated)#
	return(list(all=predictions, valid=validation))}#
predict_mcmc = function(posteriorSample, newData) {##	Works like predict(), but for mcmc samples#	Returns the average prediction for each point in the new dataset#	#	posteriorSample: mcmc object; the posterior sample from which to produce predictions#	newData: data frame of predictors where predictions should be produced#	parPrefix = 2	parEnd = 1	#
	# predict the prob of presence for each point in newData	# assumes the FIRST parameter in posteriorSample is the intercept	predictedPrPresenceMean = mean(posteriorSample[,1])	currentCol = 2	while(currentCol <= ncol(posteriorSample)) {		ndColumn = which(colnames(newData) == substr(colnames(posteriorSample)[currentCol], parPrefix + 1, nchar(colnames(posteriorSample)[currentCol]) - parEnd))		exponent = as.integer(substr(colnames(posteriorSample)[currentCol], nchar(colnames(posteriorSample)[currentCol]), nchar(colnames(posteriorSample)[currentCol])))		predictedPrPresenceMean = predictedPrPresenceMean + mean(posteriorSample[,currentCol]) * newData[,ndColumn]^exponent				currentCol = currentCol + 1	}	predictedPrPresenceMean = inv_logit(predictedPrPresenceMean)		return(predictedPrPresenceMean)}#
inv_logit = function(x) {	inf.ind = which(x == Inf)		# negative infinity works normally, but Inf returns NaN	result = exp(x) / (1+exp(x))	result[inf.ind] = 1	return(result)}in.range = function(x, lims) x >= lims[1] & x <= lims[2]#
main()
# 5-make_figure.r# #   Copyright 2014 Matthew V Talluto, Isabelle Boulangeat, Dominique Gravel# #   This program is free software; you can redistribute it and/or modify#   it under the terms of the GNU General Public License as published by#   the Free Software Foundation; either version 3 of the License, or (at#   your option) any later version.#   #   This program is distributed in the hope that it will be useful, but#   WITHOUT ANY WARRANTY; without even the implied warranty of#   MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU#   General Public License for more details.# #   You should have received a copy of the GNU General Public License#   along with this program; if not, write to the Free Software#   Foundation, Inc., 51 Franklin Street, Fifth Floor, Boston, MA 02110-1301, USA.##### produce the figure for the second example###
main = function(){	require(fields)	require(rgdal)	require(coda)#
	load("dat/naive_model.rdata")	intPredictions = read.csv("results/integratedStats.csv")	load("results/integratedModel.rdata")#
	predictions = process_predictions(maple, naiveModel, intPredictions, integratedModel)	ocean = readOGR(dsn="dat/ne_50m_ocean", layer="ne_50m_ocean")	lakes = readOGR(dsn="dat/ne_50m_lakes", layer="ne_50m_lakes")	mapleRange = readOGR(dsn="dat/acersacr", layer="acersacr")	# grab specific lakes	lkNames = c("Huron", "Michigan", "Superior", "Ontario", "Erie", "St. Clair")	grLakes = lakes[as.integer(sapply(lkNames, grep, lakes$name)),]	pdfFileName = "ex2.pdf"	pdfWidth = 7.5	pdfHeight = 6	titleCEX = 0.7#
	# which columns to loop thru for mean and errors	meanCols = c(5,11)	SECols = meanCols + 1	## pick the data to display	latLimits = c(27,65)	longLimits = c(-105, -55)	predictionsSub = subset(predictions$all, in.range(lat, latLimits) & in.range(long, longLimits))	mapleAllSub = subset(maple$all, in.range(lat, latLimits) & in.range(long, longLimits))	latitude = predictionsSub[,2]	longitude = predictionsSub[,1]	meanPredictions = cbind(mapleAllSub$Phenofit_HadA2, predictionsSub[,meanCols])	errorPredictions = predictionsSub[,SECols]	## plotting settings	meanZlims = c(0,1)	meanColors = colorRampPalette(c("#ffffff", "#bdc9e1", "#045a8d", "#33338d", "#cc99ff"), interpolate='spline', bias=1, space="rgb")(200)	meanTitles = c("A. Phenofit", "B. Naive SDM", "D. Integrated")	errorTitles = c("C. Naive SDM SE", "E. Integrated SE")	meanScaleTitle = "Suitability"	errorZlims = range(errorPredictions)	errorColors = colorRampPalette(c("#ffffff", "#ffffb2", "#fecc5c", "#fd8d3c", "#e31a1c"), interpolate='spline', space="rgb", bias=1.3)(200)	errorScaleTitle = "Posterior Standard Error"	#
	# produce the plot#	pdf(file=pdfFileName, width=pdfWidth,height=pdfHeight)	quartz(width=pdfWidth,height=pdfHeight)	rangeBorder = '#FF3333dd'	rangeLwd = 1.5	plotLayout = matrix(c(		1,2,3,		6,4,5,		7,4,5),	  byrow=T, nrow=3)	layout(plotLayout, heights=c(1, 0.5, 0.5))	par(mar=c(1,1,1,1))	for(i in 1:ncol(meanPredictions)) {		quilt.plot(longitude, latitude, meanPredictions[,i], col=meanColors, zlim=meanZlims, add.legend=F, xaxt='n', yaxt='n', useRaster=T)		plot(ocean, col="white", add=T)		plot(asRange[c(1,3,47,43),], border=rangeBorder, col="#FF555500", add=T, lwd=rangeLwd)		plot(grLakes, col="white", add=T)		mtext(meanTitles[i], adj=0, cex = titleCEX)	}	for(i in 1:ncol(errorPredictions)) {		quilt.plot(longitude, latitude, errorPredictions[,i], col=errorColors, zlim=errorZlims, add.legend=F, xaxt='n', yaxt='n', useRaster=T)		plot(ocean, col="white", add=T)		plot(asRange[c(1,3,47,43),], border=rangeBorder, col="#FF555500", add=T, lwd=rangeLwd)		plot(grLakes, col="white", add=T)		mtext(errorTitles[i], adj=0, cex = titleCEX)	}	## scale bars	par(mar=c(5,1,3,1))	image(x=seq(meanZlims[1],meanZlims[2],length.out=101), z=matrix(seq(meanZlims[1], meanZlims[2],length.out=100), 		nrow=100, ncol=1), zlim=meanZlims, col=meanColors, yaxt='n', xlab='', ylab='', useRaster=T)	mtext(meanScaleTitle, line=0.5, cex = titleCEX)	image(x=seq(errorZlims[1],errorZlims[2],length.out=101), z=matrix(seq(errorZlims[1], errorZlims[2],length.out=100), 		nrow=100, ncol=1), zlim=errorZlims, col=errorColors, yaxt='n', xlab='', ylab='', useRaster=T)	mtext(errorScaleTitle, line=0.5, cex = titleCEX)#	dev.off()}#
process_predictions = function(maple, naiveModel, intPredictions, intPosterior){##	builds an object containing the predictions of all models, both for all of the#	original data points (in result$all) and for the validation points (result$valid)##	maple: the same maple object saved in step 1#	naiveModel: the glm object representing the naive model#	intPredictions: a data frame of predictions (produced in step 4)#	intPosterior: the posterior samples from the integrated model, produced by step 3#	require(pROC)	# extract only the relevant climate variables	presClimate = maple$all[,which(colnames(maple$calib) %in% 		unique(naiveModel$variables$varNames))]	futClimate = maple$all[,which(substr(colnames(maple$calib),5, nchar(colnames(maple$calib)))		%in% unique(naiveModel$variables$varNames))]	validationClimate = maple$valid[,which(colnames(maple$calib) %in% 		unique(naiveModel$variables$varNames))]	colnames(futClimate) = colnames(presClimate)	# apply the transformations used in the calibration data to the projection datasets	presClimate = as.data.frame(sapply(names(presClimate), function(name) {		maple$transformations[[name]]$forward(presClimate[,name])}))	futClimate = as.data.frame(sapply(names(futClimate), function(name) {		maple$transformations[[name]]$forward(futClimate[,name])}))	validationClimate = as.data.frame(sapply(names(validationClimate), function(name) {		maple$transformations[[name]]$forward(validationClimate[,name])}))	# produce predictions for the naive model	naivePresPred = predict(naiveModel$model, newdata=presClimate, type='response', se.fit=TRUE)	naiveFutPred = predict(naiveModel$model, newdata=futClimate, type='response', se.fit=TRUE)	naiveValidPred = predict(naiveModel$model, newdata=validationClimate, type='response', se.fit=FALSE)	# wrap everything into a data frame	predictions = cbind(maple$all[,1:2], naivePresPred$fit, naivePresPred$se.fit, 		naiveFutPred$fit, naiveFutPred$se.fit, intPredictions)	colnames(predictions) = c("long", "lat", 		'naivePresent', 'naivePresentSE', 'naiveFuture', 'naiveFutureSE',		'intPresent', 'intPresentSE', 'intPresentLower', 'intPresentUpper',		'intFuture', 'intFutureSE', 'intFutureLower', 'intFutureUpper')	# validation	intValidPred = predict_mcmc(intPosterior, validationClimate)	validation = list(data = cbind(maple$valid[,1:5], naiveValidPred, intValidPred))	colnames(validation$data) = c('long', 'lat', 'presence', 'phenofitPres', 'phenofitFut', 'naive', 'integrated')	validation$naiveROC = roc(validation$data$presence, validation$data$naive)	validation$phenofitROC = roc(validation$data$presence, validation$data$phenofitPres)	validation$integratedROC = roc(validation$data$presence, validation$data$integrated)#
	return(list(all=predictions, valid=validation))}#
predict_mcmc = function(posteriorSample, newData) {##	Works like predict(), but for mcmc samples#	Returns the average prediction for each point in the new dataset#	#	posteriorSample: mcmc object; the posterior sample from which to produce predictions#	newData: data frame of predictors where predictions should be produced#	parPrefix = 2	parEnd = 1	#
	# predict the prob of presence for each point in newData	# assumes the FIRST parameter in posteriorSample is the intercept	predictedPrPresenceMean = mean(posteriorSample[,1])	currentCol = 2	while(currentCol <= ncol(posteriorSample)) {		ndColumn = which(colnames(newData) == substr(colnames(posteriorSample)[currentCol], parPrefix + 1, nchar(colnames(posteriorSample)[currentCol]) - parEnd))		exponent = as.integer(substr(colnames(posteriorSample)[currentCol], nchar(colnames(posteriorSample)[currentCol]), nchar(colnames(posteriorSample)[currentCol])))		predictedPrPresenceMean = predictedPrPresenceMean + mean(posteriorSample[,currentCol]) * newData[,ndColumn]^exponent				currentCol = currentCol + 1	}	predictedPrPresenceMean = inv_logit(predictedPrPresenceMean)		return(predictedPrPresenceMean)}#
inv_logit = function(x) {	inf.ind = which(x == Inf)		# negative infinity works normally, but Inf returns NaN	result = exp(x) / (1+exp(x))	result[inf.ind] = 1	return(result)}in.range = function(x, lims) x >= lims[1] & x <= lims[2]#
main()
dev.size()
# 5-make_figure.r# #   Copyright 2014 Matthew V Talluto, Isabelle Boulangeat, Dominique Gravel# #   This program is free software; you can redistribute it and/or modify#   it under the terms of the GNU General Public License as published by#   the Free Software Foundation; either version 3 of the License, or (at#   your option) any later version.#   #   This program is distributed in the hope that it will be useful, but#   WITHOUT ANY WARRANTY; without even the implied warranty of#   MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU#   General Public License for more details.# #   You should have received a copy of the GNU General Public License#   along with this program; if not, write to the Free Software#   Foundation, Inc., 51 Franklin Street, Fifth Floor, Boston, MA 02110-1301, USA.##### produce the figure for the second example###
main = function(){	require(fields)	require(rgdal)	require(coda)#
	load("dat/naive_model.rdata")	intPredictions = read.csv("results/integratedStats.csv")	load("results/integratedModel.rdata")#
	predictions = process_predictions(maple, naiveModel, intPredictions, integratedModel)	ocean = readOGR(dsn="dat/ne_50m_ocean", layer="ne_50m_ocean")	lakes = readOGR(dsn="dat/ne_50m_lakes", layer="ne_50m_lakes")	mapleRange = readOGR(dsn="dat/acersacr", layer="acersacr")	# grab specific lakes	lkNames = c("Huron", "Michigan", "Superior", "Ontario", "Erie", "St. Clair")	grLakes = lakes[as.integer(sapply(lkNames, grep, lakes$name)),]	pdfFileName = "ex2.pdf"	pdfWidth = 7.5	pdfHeight = 5	titleCEX = 0.7#
	# which columns to loop thru for mean and errors	meanCols = c(5,11)	SECols = meanCols + 1	## pick the data to display	latLimits = c(27,65)	longLimits = c(-105, -55)	predictionsSub = subset(predictions$all, in.range(lat, latLimits) & in.range(long, longLimits))	mapleAllSub = subset(maple$all, in.range(lat, latLimits) & in.range(long, longLimits))	latitude = predictionsSub[,2]	longitude = predictionsSub[,1]	meanPredictions = cbind(mapleAllSub$Phenofit_HadA2, predictionsSub[,meanCols])	errorPredictions = predictionsSub[,SECols]	## plotting settings	meanZlims = c(0,1)	meanColors = colorRampPalette(c("#ffffff", "#bdc9e1", "#045a8d", "#33338d", "#cc99ff"), interpolate='spline', bias=1, space="rgb")(200)	meanTitles = c("A. Phenofit", "B. Naive SDM", "D. Integrated")	errorTitles = c("C. Naive SDM SE", "E. Integrated SE")	meanScaleTitle = "Suitability"	errorZlims = range(errorPredictions)	errorColors = colorRampPalette(c("#ffffff", "#ffffb2", "#fecc5c", "#fd8d3c", "#e31a1c"), interpolate='spline', space="rgb", bias=1.3)(200)	errorScaleTitle = "Posterior Standard Error"	#
	# produce the plot#	pdf(file=pdfFileName, width=pdfWidth,height=pdfHeight)	quartz(width=pdfWidth,height=pdfHeight)	rangeBorder = '#FF3333bb'	rangeLwd = 1.2	plotLayout = matrix(c(		1,2,3,		6,4,5,		7,4,5),	  byrow=T, nrow=3)	layout(plotLayout, heights=c(1, 0.5, 0.5))	par(mar=c(1,1,1,1))	for(i in 1:ncol(meanPredictions)) {		quilt.plot(longitude, latitude, meanPredictions[,i], col=meanColors, zlim=meanZlims, add.legend=F, xaxt='n', yaxt='n', useRaster=T)		plot(ocean, col="white", add=T)		plot(asRange[c(1,3,47,43),], border=rangeBorder, col="#FF555500", add=T, lwd=rangeLwd)		plot(grLakes, col="white", add=T)		mtext(meanTitles[i], adj=0, cex = titleCEX)	}	for(i in 1:ncol(errorPredictions)) {		quilt.plot(longitude, latitude, errorPredictions[,i], col=errorColors, zlim=errorZlims, add.legend=F, xaxt='n', yaxt='n', useRaster=T)		plot(ocean, col="white", add=T)		plot(asRange[c(1,3,47,43),], border=rangeBorder, col="#FF555500", add=T, lwd=rangeLwd)		plot(grLakes, col="white", add=T)		mtext(errorTitles[i], adj=0, cex = titleCEX)	}	## scale bars	par(mar=c(5,1,3,1))	image(x=seq(meanZlims[1],meanZlims[2],length.out=101), z=matrix(seq(meanZlims[1], meanZlims[2],length.out=100), 		nrow=100, ncol=1), zlim=meanZlims, col=meanColors, yaxt='n', xlab='', ylab='', useRaster=T)	mtext(meanScaleTitle, line=0.5, cex = titleCEX)	image(x=seq(errorZlims[1],errorZlims[2],length.out=101), z=matrix(seq(errorZlims[1], errorZlims[2],length.out=100), 		nrow=100, ncol=1), zlim=errorZlims, col=errorColors, yaxt='n', xlab='', ylab='', useRaster=T)	mtext(errorScaleTitle, line=0.5, cex = titleCEX)#	dev.off()}#
process_predictions = function(maple, naiveModel, intPredictions, intPosterior){##	builds an object containing the predictions of all models, both for all of the#	original data points (in result$all) and for the validation points (result$valid)##	maple: the same maple object saved in step 1#	naiveModel: the glm object representing the naive model#	intPredictions: a data frame of predictions (produced in step 4)#	intPosterior: the posterior samples from the integrated model, produced by step 3#	require(pROC)	# extract only the relevant climate variables	presClimate = maple$all[,which(colnames(maple$calib) %in% 		unique(naiveModel$variables$varNames))]	futClimate = maple$all[,which(substr(colnames(maple$calib),5, nchar(colnames(maple$calib)))		%in% unique(naiveModel$variables$varNames))]	validationClimate = maple$valid[,which(colnames(maple$calib) %in% 		unique(naiveModel$variables$varNames))]	colnames(futClimate) = colnames(presClimate)	# apply the transformations used in the calibration data to the projection datasets	presClimate = as.data.frame(sapply(names(presClimate), function(name) {		maple$transformations[[name]]$forward(presClimate[,name])}))	futClimate = as.data.frame(sapply(names(futClimate), function(name) {		maple$transformations[[name]]$forward(futClimate[,name])}))	validationClimate = as.data.frame(sapply(names(validationClimate), function(name) {		maple$transformations[[name]]$forward(validationClimate[,name])}))	# produce predictions for the naive model	naivePresPred = predict(naiveModel$model, newdata=presClimate, type='response', se.fit=TRUE)	naiveFutPred = predict(naiveModel$model, newdata=futClimate, type='response', se.fit=TRUE)	naiveValidPred = predict(naiveModel$model, newdata=validationClimate, type='response', se.fit=FALSE)	# wrap everything into a data frame	predictions = cbind(maple$all[,1:2], naivePresPred$fit, naivePresPred$se.fit, 		naiveFutPred$fit, naiveFutPred$se.fit, intPredictions)	colnames(predictions) = c("long", "lat", 		'naivePresent', 'naivePresentSE', 'naiveFuture', 'naiveFutureSE',		'intPresent', 'intPresentSE', 'intPresentLower', 'intPresentUpper',		'intFuture', 'intFutureSE', 'intFutureLower', 'intFutureUpper')	# validation	intValidPred = predict_mcmc(intPosterior, validationClimate)	validation = list(data = cbind(maple$valid[,1:5], naiveValidPred, intValidPred))	colnames(validation$data) = c('long', 'lat', 'presence', 'phenofitPres', 'phenofitFut', 'naive', 'integrated')	validation$naiveROC = roc(validation$data$presence, validation$data$naive)	validation$phenofitROC = roc(validation$data$presence, validation$data$phenofitPres)	validation$integratedROC = roc(validation$data$presence, validation$data$integrated)#
	return(list(all=predictions, valid=validation))}#
predict_mcmc = function(posteriorSample, newData) {##	Works like predict(), but for mcmc samples#	Returns the average prediction for each point in the new dataset#	#	posteriorSample: mcmc object; the posterior sample from which to produce predictions#	newData: data frame of predictors where predictions should be produced#	parPrefix = 2	parEnd = 1	#
	# predict the prob of presence for each point in newData	# assumes the FIRST parameter in posteriorSample is the intercept	predictedPrPresenceMean = mean(posteriorSample[,1])	currentCol = 2	while(currentCol <= ncol(posteriorSample)) {		ndColumn = which(colnames(newData) == substr(colnames(posteriorSample)[currentCol], parPrefix + 1, nchar(colnames(posteriorSample)[currentCol]) - parEnd))		exponent = as.integer(substr(colnames(posteriorSample)[currentCol], nchar(colnames(posteriorSample)[currentCol]), nchar(colnames(posteriorSample)[currentCol])))		predictedPrPresenceMean = predictedPrPresenceMean + mean(posteriorSample[,currentCol]) * newData[,ndColumn]^exponent				currentCol = currentCol + 1	}	predictedPrPresenceMean = inv_logit(predictedPrPresenceMean)		return(predictedPrPresenceMean)}#
inv_logit = function(x) {	inf.ind = which(x == Inf)		# negative infinity works normally, but Inf returns NaN	result = exp(x) / (1+exp(x))	result[inf.ind] = 1	return(result)}in.range = function(x, lims) x >= lims[1] & x <= lims[2]#
main()
# 5-make_figure.r# #   Copyright 2014 Matthew V Talluto, Isabelle Boulangeat, Dominique Gravel# #   This program is free software; you can redistribute it and/or modify#   it under the terms of the GNU General Public License as published by#   the Free Software Foundation; either version 3 of the License, or (at#   your option) any later version.#   #   This program is distributed in the hope that it will be useful, but#   WITHOUT ANY WARRANTY; without even the implied warranty of#   MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU#   General Public License for more details.# #   You should have received a copy of the GNU General Public License#   along with this program; if not, write to the Free Software#   Foundation, Inc., 51 Franklin Street, Fifth Floor, Boston, MA 02110-1301, USA.##### produce the figure for the second example###
main = function(){	require(fields)	require(rgdal)	require(coda)#
	load("dat/naive_model.rdata")	intPredictions = read.csv("results/integratedStats.csv")	load("results/integratedModel.rdata")#
	predictions = process_predictions(maple, naiveModel, intPredictions, integratedModel)	ocean = readOGR(dsn="dat/ne_50m_ocean", layer="ne_50m_ocean")	lakes = readOGR(dsn="dat/ne_50m_lakes", layer="ne_50m_lakes")	mapleRange = readOGR(dsn="dat/acersacr", layer="acersacr")	# grab specific lakes	lkNames = c("Huron", "Michigan", "Superior", "Ontario", "Erie", "St. Clair")	grLakes = lakes[as.integer(sapply(lkNames, grep, lakes$name)),]	pdfFileName = "ex2.pdf"	pdfWidth = 7.5	pdfHeight = 5	titleCEX = 0.7#
	# which columns to loop thru for mean and errors	meanCols = c(5,11)	SECols = meanCols + 1	## pick the data to display	latLimits = c(27,65)	longLimits = c(-105, -55)	predictionsSub = subset(predictions$all, in.range(lat, latLimits) & in.range(long, longLimits))	mapleAllSub = subset(maple$all, in.range(lat, latLimits) & in.range(long, longLimits))	latitude = predictionsSub[,2]	longitude = predictionsSub[,1]	meanPredictions = cbind(mapleAllSub$Phenofit_HadA2, predictionsSub[,meanCols])	errorPredictions = predictionsSub[,SECols]	## plotting settings	meanZlims = c(0,1)	meanColors = colorRampPalette(c("#ffffff", "#bdc9e1", "#045a8d", "#33338d", "#cc99ff"), interpolate='spline', bias=1, space="rgb")(200)	meanTitles = c("A. Phenofit", "B. Naive SDM", "D. Integrated")	errorTitles = c("C. Naive SDM SE", "E. Integrated SE")	meanScaleTitle = "Suitability"	errorZlims = range(errorPredictions)	errorColors = colorRampPalette(c("#ffffff", "#ffffb2", "#fecc5c", "#fd8d3c", "#e31a1c"), interpolate='spline', space="rgb", bias=1.3)(200)	errorScaleTitle = "Posterior Standard Error"	#
	# produce the plot#	pdf(file=pdfFileName, width=pdfWidth,height=pdfHeight)	quartz(width=pdfWidth,height=pdfHeight)	rangeBorder = '#FF3333bb'	rangeLwd = 1.2	rangeCol = "#66666666"	plotLayout = matrix(c(		1,2,3,		6,4,5,		7,4,5),	  byrow=T, nrow=3)	layout(plotLayout, heights=c(1, 0.5, 0.5))	par(mar=c(1,1,1,1))	for(i in 1:ncol(meanPredictions)) {		quilt.plot(longitude, latitude, meanPredictions[,i], col=meanColors, zlim=meanZlims, add.legend=F, xaxt='n', yaxt='n', useRaster=T)		plot(ocean, col="white", add=T)		plot(asRange[c(1,3,47,43),], border=rangeBorder, col=rangeCol, add=T, lwd=rangeLwd)		plot(grLakes, col="white", add=T)		mtext(meanTitles[i], adj=0, cex = titleCEX)	}	for(i in 1:ncol(errorPredictions)) {		quilt.plot(longitude, latitude, errorPredictions[,i], col=errorColors, zlim=errorZlims, add.legend=F, xaxt='n', yaxt='n', useRaster=T)		plot(ocean, col="white", add=T)		plot(asRange[c(1,3,47,43),], border=rangeBorder, col=rangeCol, add=T, lwd=rangeLwd)		plot(grLakes, col="white", add=T)		mtext(errorTitles[i], adj=0, cex = titleCEX)	}	## scale bars	par(mar=c(5,1,3,1))	image(x=seq(meanZlims[1],meanZlims[2],length.out=101), z=matrix(seq(meanZlims[1], meanZlims[2],length.out=100), 		nrow=100, ncol=1), zlim=meanZlims, col=meanColors, yaxt='n', xlab='', ylab='', useRaster=T)	mtext(meanScaleTitle, line=0.5, cex = titleCEX)	image(x=seq(errorZlims[1],errorZlims[2],length.out=101), z=matrix(seq(errorZlims[1], errorZlims[2],length.out=100), 		nrow=100, ncol=1), zlim=errorZlims, col=errorColors, yaxt='n', xlab='', ylab='', useRaster=T)	mtext(errorScaleTitle, line=0.5, cex = titleCEX)#	dev.off()}#
process_predictions = function(maple, naiveModel, intPredictions, intPosterior){##	builds an object containing the predictions of all models, both for all of the#	original data points (in result$all) and for the validation points (result$valid)##	maple: the same maple object saved in step 1#	naiveModel: the glm object representing the naive model#	intPredictions: a data frame of predictions (produced in step 4)#	intPosterior: the posterior samples from the integrated model, produced by step 3#	require(pROC)	# extract only the relevant climate variables	presClimate = maple$all[,which(colnames(maple$calib) %in% 		unique(naiveModel$variables$varNames))]	futClimate = maple$all[,which(substr(colnames(maple$calib),5, nchar(colnames(maple$calib)))		%in% unique(naiveModel$variables$varNames))]	validationClimate = maple$valid[,which(colnames(maple$calib) %in% 		unique(naiveModel$variables$varNames))]	colnames(futClimate) = colnames(presClimate)	# apply the transformations used in the calibration data to the projection datasets	presClimate = as.data.frame(sapply(names(presClimate), function(name) {		maple$transformations[[name]]$forward(presClimate[,name])}))	futClimate = as.data.frame(sapply(names(futClimate), function(name) {		maple$transformations[[name]]$forward(futClimate[,name])}))	validationClimate = as.data.frame(sapply(names(validationClimate), function(name) {		maple$transformations[[name]]$forward(validationClimate[,name])}))	# produce predictions for the naive model	naivePresPred = predict(naiveModel$model, newdata=presClimate, type='response', se.fit=TRUE)	naiveFutPred = predict(naiveModel$model, newdata=futClimate, type='response', se.fit=TRUE)	naiveValidPred = predict(naiveModel$model, newdata=validationClimate, type='response', se.fit=FALSE)	# wrap everything into a data frame	predictions = cbind(maple$all[,1:2], naivePresPred$fit, naivePresPred$se.fit, 		naiveFutPred$fit, naiveFutPred$se.fit, intPredictions)	colnames(predictions) = c("long", "lat", 		'naivePresent', 'naivePresentSE', 'naiveFuture', 'naiveFutureSE',		'intPresent', 'intPresentSE', 'intPresentLower', 'intPresentUpper',		'intFuture', 'intFutureSE', 'intFutureLower', 'intFutureUpper')	# validation	intValidPred = predict_mcmc(intPosterior, validationClimate)	validation = list(data = cbind(maple$valid[,1:5], naiveValidPred, intValidPred))	colnames(validation$data) = c('long', 'lat', 'presence', 'phenofitPres', 'phenofitFut', 'naive', 'integrated')	validation$naiveROC = roc(validation$data$presence, validation$data$naive)	validation$phenofitROC = roc(validation$data$presence, validation$data$phenofitPres)	validation$integratedROC = roc(validation$data$presence, validation$data$integrated)#
	return(list(all=predictions, valid=validation))}#
predict_mcmc = function(posteriorSample, newData) {##	Works like predict(), but for mcmc samples#	Returns the average prediction for each point in the new dataset#	#	posteriorSample: mcmc object; the posterior sample from which to produce predictions#	newData: data frame of predictors where predictions should be produced#	parPrefix = 2	parEnd = 1	#
	# predict the prob of presence for each point in newData	# assumes the FIRST parameter in posteriorSample is the intercept	predictedPrPresenceMean = mean(posteriorSample[,1])	currentCol = 2	while(currentCol <= ncol(posteriorSample)) {		ndColumn = which(colnames(newData) == substr(colnames(posteriorSample)[currentCol], parPrefix + 1, nchar(colnames(posteriorSample)[currentCol]) - parEnd))		exponent = as.integer(substr(colnames(posteriorSample)[currentCol], nchar(colnames(posteriorSample)[currentCol]), nchar(colnames(posteriorSample)[currentCol])))		predictedPrPresenceMean = predictedPrPresenceMean + mean(posteriorSample[,currentCol]) * newData[,ndColumn]^exponent				currentCol = currentCol + 1	}	predictedPrPresenceMean = inv_logit(predictedPrPresenceMean)		return(predictedPrPresenceMean)}#
inv_logit = function(x) {	inf.ind = which(x == Inf)		# negative infinity works normally, but Inf returns NaN	result = exp(x) / (1+exp(x))	result[inf.ind] = 1	return(result)}in.range = function(x, lims) x >= lims[1] & x <= lims[2]#
main()
# 5-make_figure.r# #   Copyright 2014 Matthew V Talluto, Isabelle Boulangeat, Dominique Gravel# #   This program is free software; you can redistribute it and/or modify#   it under the terms of the GNU General Public License as published by#   the Free Software Foundation; either version 3 of the License, or (at#   your option) any later version.#   #   This program is distributed in the hope that it will be useful, but#   WITHOUT ANY WARRANTY; without even the implied warranty of#   MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU#   General Public License for more details.# #   You should have received a copy of the GNU General Public License#   along with this program; if not, write to the Free Software#   Foundation, Inc., 51 Franklin Street, Fifth Floor, Boston, MA 02110-1301, USA.##### produce the figure for the second example###
main = function(){	require(fields)	require(rgdal)	require(coda)#
	load("dat/naive_model.rdata")	intPredictions = read.csv("results/integratedStats.csv")	load("results/integratedModel.rdata")#
	predictions = process_predictions(maple, naiveModel, intPredictions, integratedModel)	ocean = readOGR(dsn="dat/ne_50m_ocean", layer="ne_50m_ocean")	lakes = readOGR(dsn="dat/ne_50m_lakes", layer="ne_50m_lakes")	mapleRange = readOGR(dsn="dat/acersacr", layer="acersacr")	# grab specific lakes	lkNames = c("Huron", "Michigan", "Superior", "Ontario", "Erie", "St. Clair")	grLakes = lakes[as.integer(sapply(lkNames, grep, lakes$name)),]	pdfFileName = "ex2.pdf"	pdfWidth = 7.5	pdfHeight = 5.5	titleCEX = 0.7#
	# which columns to loop thru for mean and errors	meanCols = c(5,11)	SECols = meanCols + 1	## pick the data to display	latLimits = c(27,65)	longLimits = c(-105, -55)	predictionsSub = subset(predictions$all, in.range(lat, latLimits) & in.range(long, longLimits))	mapleAllSub = subset(maple$all, in.range(lat, latLimits) & in.range(long, longLimits))	latitude = predictionsSub[,2]	longitude = predictionsSub[,1]	meanPredictions = cbind(mapleAllSub$Phenofit_HadA2, predictionsSub[,meanCols])	errorPredictions = predictionsSub[,SECols]	## plotting settings	meanZlims = c(0,1)	meanColors = colorRampPalette(c("#ffffff", "#bdc9e1", "#045a8d", "#33338d", "#cc99ff"), interpolate='spline', bias=1, space="rgb")(200)	meanTitles = c("A. Phenofit", "B. Naive SDM", "D. Integrated")	errorTitles = c("C. Naive SDM SE", "E. Integrated SE")	meanScaleTitle = "Suitability"	errorZlims = range(errorPredictions)	errorColors = colorRampPalette(c("#ffffff", "#ffffb2", "#fecc5c", "#fd8d3c", "#e31a1c"), interpolate='spline', space="rgb", bias=1.3)(200)	errorScaleTitle = "Posterior Standard Error"	#
	# produce the plot#	pdf(file=pdfFileName, width=pdfWidth,height=pdfHeight)	quartz(width=pdfWidth,height=pdfHeight)	rangeBorder = '#FF3333bb'	rangeLwd = 1.2	rangeCol = "#66666600"	plotLayout = matrix(c(		1,2,3,		6,4,5,		7,4,5),	  byrow=T, nrow=3)	layout(plotLayout, heights=c(1, 0.5, 0.5))	par(mar=c(1,1,1,1))	for(i in 1:ncol(meanPredictions)) {		quilt.plot(longitude, latitude, meanPredictions[,i], col=meanColors, zlim=meanZlims, add.legend=F, xaxt='n', yaxt='n', useRaster=T)		plot(ocean, col="white", add=T)		plot(asRange[c(1,3,47,43),], border=rangeBorder, col=rangeCol, add=T, lwd=rangeLwd)		plot(grLakes, col="white", add=T)		mtext(meanTitles[i], adj=0, cex = titleCEX)	}	for(i in 1:ncol(errorPredictions)) {		quilt.plot(longitude, latitude, errorPredictions[,i], col=errorColors, zlim=errorZlims, add.legend=F, xaxt='n', yaxt='n', useRaster=T)		plot(ocean, col="white", add=T)		plot(asRange[c(1,3,47,43),], border=rangeBorder, col=rangeCol, add=T, lwd=rangeLwd)		plot(grLakes, col="white", add=T)		mtext(errorTitles[i], adj=0, cex = titleCEX)	}	## scale bars	par(mar=c(5,1,3,1))	image(x=seq(meanZlims[1],meanZlims[2],length.out=101), z=matrix(seq(meanZlims[1], meanZlims[2],length.out=100), 		nrow=100, ncol=1), zlim=meanZlims, col=meanColors, yaxt='n', xlab='', ylab='', useRaster=T)	mtext(meanScaleTitle, line=0.5, cex = titleCEX)	image(x=seq(errorZlims[1],errorZlims[2],length.out=101), z=matrix(seq(errorZlims[1], errorZlims[2],length.out=100), 		nrow=100, ncol=1), zlim=errorZlims, col=errorColors, yaxt='n', xlab='', ylab='', useRaster=T)	mtext(errorScaleTitle, line=0.5, cex = titleCEX)#	dev.off()}#
process_predictions = function(maple, naiveModel, intPredictions, intPosterior){##	builds an object containing the predictions of all models, both for all of the#	original data points (in result$all) and for the validation points (result$valid)##	maple: the same maple object saved in step 1#	naiveModel: the glm object representing the naive model#	intPredictions: a data frame of predictions (produced in step 4)#	intPosterior: the posterior samples from the integrated model, produced by step 3#	require(pROC)	# extract only the relevant climate variables	presClimate = maple$all[,which(colnames(maple$calib) %in% 		unique(naiveModel$variables$varNames))]	futClimate = maple$all[,which(substr(colnames(maple$calib),5, nchar(colnames(maple$calib)))		%in% unique(naiveModel$variables$varNames))]	validationClimate = maple$valid[,which(colnames(maple$calib) %in% 		unique(naiveModel$variables$varNames))]	colnames(futClimate) = colnames(presClimate)	# apply the transformations used in the calibration data to the projection datasets	presClimate = as.data.frame(sapply(names(presClimate), function(name) {		maple$transformations[[name]]$forward(presClimate[,name])}))	futClimate = as.data.frame(sapply(names(futClimate), function(name) {		maple$transformations[[name]]$forward(futClimate[,name])}))	validationClimate = as.data.frame(sapply(names(validationClimate), function(name) {		maple$transformations[[name]]$forward(validationClimate[,name])}))	# produce predictions for the naive model	naivePresPred = predict(naiveModel$model, newdata=presClimate, type='response', se.fit=TRUE)	naiveFutPred = predict(naiveModel$model, newdata=futClimate, type='response', se.fit=TRUE)	naiveValidPred = predict(naiveModel$model, newdata=validationClimate, type='response', se.fit=FALSE)	# wrap everything into a data frame	predictions = cbind(maple$all[,1:2], naivePresPred$fit, naivePresPred$se.fit, 		naiveFutPred$fit, naiveFutPred$se.fit, intPredictions)	colnames(predictions) = c("long", "lat", 		'naivePresent', 'naivePresentSE', 'naiveFuture', 'naiveFutureSE',		'intPresent', 'intPresentSE', 'intPresentLower', 'intPresentUpper',		'intFuture', 'intFutureSE', 'intFutureLower', 'intFutureUpper')	# validation	intValidPred = predict_mcmc(intPosterior, validationClimate)	validation = list(data = cbind(maple$valid[,1:5], naiveValidPred, intValidPred))	colnames(validation$data) = c('long', 'lat', 'presence', 'phenofitPres', 'phenofitFut', 'naive', 'integrated')	validation$naiveROC = roc(validation$data$presence, validation$data$naive)	validation$phenofitROC = roc(validation$data$presence, validation$data$phenofitPres)	validation$integratedROC = roc(validation$data$presence, validation$data$integrated)#
	return(list(all=predictions, valid=validation))}#
predict_mcmc = function(posteriorSample, newData) {##	Works like predict(), but for mcmc samples#	Returns the average prediction for each point in the new dataset#	#	posteriorSample: mcmc object; the posterior sample from which to produce predictions#	newData: data frame of predictors where predictions should be produced#	parPrefix = 2	parEnd = 1	#
	# predict the prob of presence for each point in newData	# assumes the FIRST parameter in posteriorSample is the intercept	predictedPrPresenceMean = mean(posteriorSample[,1])	currentCol = 2	while(currentCol <= ncol(posteriorSample)) {		ndColumn = which(colnames(newData) == substr(colnames(posteriorSample)[currentCol], parPrefix + 1, nchar(colnames(posteriorSample)[currentCol]) - parEnd))		exponent = as.integer(substr(colnames(posteriorSample)[currentCol], nchar(colnames(posteriorSample)[currentCol]), nchar(colnames(posteriorSample)[currentCol])))		predictedPrPresenceMean = predictedPrPresenceMean + mean(posteriorSample[,currentCol]) * newData[,ndColumn]^exponent				currentCol = currentCol + 1	}	predictedPrPresenceMean = inv_logit(predictedPrPresenceMean)		return(predictedPrPresenceMean)}#
inv_logit = function(x) {	inf.ind = which(x == Inf)		# negative infinity works normally, but Inf returns NaN	result = exp(x) / (1+exp(x))	result[inf.ind] = 1	return(result)}in.range = function(x, lims) x >= lims[1] & x <= lims[2]#
main()
# 5-make_figure.r# #   Copyright 2014 Matthew V Talluto, Isabelle Boulangeat, Dominique Gravel# #   This program is free software; you can redistribute it and/or modify#   it under the terms of the GNU General Public License as published by#   the Free Software Foundation; either version 3 of the License, or (at#   your option) any later version.#   #   This program is distributed in the hope that it will be useful, but#   WITHOUT ANY WARRANTY; without even the implied warranty of#   MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU#   General Public License for more details.# #   You should have received a copy of the GNU General Public License#   along with this program; if not, write to the Free Software#   Foundation, Inc., 51 Franklin Street, Fifth Floor, Boston, MA 02110-1301, USA.##### produce the figure for the second example###
main = function(){	require(fields)	require(rgdal)	require(coda)#
	load("dat/naive_model.rdata")	intPredictions = read.csv("results/integratedStats.csv")	load("results/integratedModel.rdata")#
	predictions = process_predictions(maple, naiveModel, intPredictions, integratedModel)	ocean = readOGR(dsn="dat/ne_50m_ocean", layer="ne_50m_ocean")	lakes = readOGR(dsn="dat/ne_50m_lakes", layer="ne_50m_lakes")	mapleRange = readOGR(dsn="dat/acersacr", layer="acersacr")	# grab specific lakes	lkNames = c("Huron", "Michigan", "Superior", "Ontario", "Erie", "St. Clair")	grLakes = lakes[as.integer(sapply(lkNames, grep, lakes$name)),]	pdfFileName = "ex2.pdf"	pdfWidth = 7.5	pdfHeight = 5.25	titleCEX = 0.7#
	# which columns to loop thru for mean and errors	meanCols = c(5,11)	SECols = meanCols + 1	## pick the data to display	latLimits = c(27,65)	longLimits = c(-105, -55)	predictionsSub = subset(predictions$all, in.range(lat, latLimits) & in.range(long, longLimits))	mapleAllSub = subset(maple$all, in.range(lat, latLimits) & in.range(long, longLimits))	latitude = predictionsSub[,2]	longitude = predictionsSub[,1]	meanPredictions = cbind(mapleAllSub$Phenofit_HadA2, predictionsSub[,meanCols])	errorPredictions = predictionsSub[,SECols]	## plotting settings	meanZlims = c(0,1)	meanColors = colorRampPalette(c("#ffffff", "#bdc9e1", "#045a8d", "#33338d", "#cc99ff"), interpolate='spline', bias=1, space="rgb")(200)	meanTitles = c("A. Phenofit", "B. Naive SDM", "D. Integrated")	errorTitles = c("C. Naive SDM SE", "E. Integrated SE")	meanScaleTitle = "Suitability"	errorZlims = range(errorPredictions)	errorColors = colorRampPalette(c("#ffffff", "#ffffb2", "#fecc5c", "#fd8d3c", "#e31a1c"), interpolate='spline', space="rgb", bias=1.3)(200)	errorScaleTitle = "Posterior Standard Error"	#
	# produce the plot#	pdf(file=pdfFileName, width=pdfWidth,height=pdfHeight)	quartz(width=pdfWidth,height=pdfHeight)	rangeBorder = '#FF3333bb'	rangeLwd = 1.2	rangeCol = "#66666600"	plotLayout = matrix(c(		1,2,3,		6,4,5,		7,4,5),	  byrow=T, nrow=3)	layout(plotLayout, heights=c(1, 0.5, 0.5))	par(mar=c(1,1,1,1))	for(i in 1:ncol(meanPredictions)) {		quilt.plot(longitude, latitude, meanPredictions[,i], col=meanColors, zlim=meanZlims, add.legend=F, xaxt='n', yaxt='n', useRaster=T)		plot(ocean, col="white", add=T)		plot(asRange[c(1,3,47,43),], border=rangeBorder, col=rangeCol, add=T, lwd=rangeLwd)		plot(grLakes, col="white", add=T)		mtext(meanTitles[i], adj=0, cex = titleCEX)	}	for(i in 1:ncol(errorPredictions)) {		quilt.plot(longitude, latitude, errorPredictions[,i], col=errorColors, zlim=errorZlims, add.legend=F, xaxt='n', yaxt='n', useRaster=T)		plot(ocean, col="white", add=T)		plot(asRange[c(1,3,47,43),], border=rangeBorder, col=rangeCol, add=T, lwd=rangeLwd)		plot(grLakes, col="white", add=T)		mtext(errorTitles[i], adj=0, cex = titleCEX)	}	## scale bars	par(mar=c(5,1,3,1))	image(x=seq(meanZlims[1],meanZlims[2],length.out=101), z=matrix(seq(meanZlims[1], meanZlims[2],length.out=100), 		nrow=100, ncol=1), zlim=meanZlims, col=meanColors, yaxt='n', xlab='', ylab='', useRaster=T)	mtext(meanScaleTitle, line=0.5, cex = titleCEX)	image(x=seq(errorZlims[1],errorZlims[2],length.out=101), z=matrix(seq(errorZlims[1], errorZlims[2],length.out=100), 		nrow=100, ncol=1), zlim=errorZlims, col=errorColors, yaxt='n', xlab='', ylab='', useRaster=T)	mtext(errorScaleTitle, line=0.5, cex = titleCEX)#	dev.off()}#
process_predictions = function(maple, naiveModel, intPredictions, intPosterior){##	builds an object containing the predictions of all models, both for all of the#	original data points (in result$all) and for the validation points (result$valid)##	maple: the same maple object saved in step 1#	naiveModel: the glm object representing the naive model#	intPredictions: a data frame of predictions (produced in step 4)#	intPosterior: the posterior samples from the integrated model, produced by step 3#	require(pROC)	# extract only the relevant climate variables	presClimate = maple$all[,which(colnames(maple$calib) %in% 		unique(naiveModel$variables$varNames))]	futClimate = maple$all[,which(substr(colnames(maple$calib),5, nchar(colnames(maple$calib)))		%in% unique(naiveModel$variables$varNames))]	validationClimate = maple$valid[,which(colnames(maple$calib) %in% 		unique(naiveModel$variables$varNames))]	colnames(futClimate) = colnames(presClimate)	# apply the transformations used in the calibration data to the projection datasets	presClimate = as.data.frame(sapply(names(presClimate), function(name) {		maple$transformations[[name]]$forward(presClimate[,name])}))	futClimate = as.data.frame(sapply(names(futClimate), function(name) {		maple$transformations[[name]]$forward(futClimate[,name])}))	validationClimate = as.data.frame(sapply(names(validationClimate), function(name) {		maple$transformations[[name]]$forward(validationClimate[,name])}))	# produce predictions for the naive model	naivePresPred = predict(naiveModel$model, newdata=presClimate, type='response', se.fit=TRUE)	naiveFutPred = predict(naiveModel$model, newdata=futClimate, type='response', se.fit=TRUE)	naiveValidPred = predict(naiveModel$model, newdata=validationClimate, type='response', se.fit=FALSE)	# wrap everything into a data frame	predictions = cbind(maple$all[,1:2], naivePresPred$fit, naivePresPred$se.fit, 		naiveFutPred$fit, naiveFutPred$se.fit, intPredictions)	colnames(predictions) = c("long", "lat", 		'naivePresent', 'naivePresentSE', 'naiveFuture', 'naiveFutureSE',		'intPresent', 'intPresentSE', 'intPresentLower', 'intPresentUpper',		'intFuture', 'intFutureSE', 'intFutureLower', 'intFutureUpper')	# validation	intValidPred = predict_mcmc(intPosterior, validationClimate)	validation = list(data = cbind(maple$valid[,1:5], naiveValidPred, intValidPred))	colnames(validation$data) = c('long', 'lat', 'presence', 'phenofitPres', 'phenofitFut', 'naive', 'integrated')	validation$naiveROC = roc(validation$data$presence, validation$data$naive)	validation$phenofitROC = roc(validation$data$presence, validation$data$phenofitPres)	validation$integratedROC = roc(validation$data$presence, validation$data$integrated)#
	return(list(all=predictions, valid=validation))}#
predict_mcmc = function(posteriorSample, newData) {##	Works like predict(), but for mcmc samples#	Returns the average prediction for each point in the new dataset#	#	posteriorSample: mcmc object; the posterior sample from which to produce predictions#	newData: data frame of predictors where predictions should be produced#	parPrefix = 2	parEnd = 1	#
	# predict the prob of presence for each point in newData	# assumes the FIRST parameter in posteriorSample is the intercept	predictedPrPresenceMean = mean(posteriorSample[,1])	currentCol = 2	while(currentCol <= ncol(posteriorSample)) {		ndColumn = which(colnames(newData) == substr(colnames(posteriorSample)[currentCol], parPrefix + 1, nchar(colnames(posteriorSample)[currentCol]) - parEnd))		exponent = as.integer(substr(colnames(posteriorSample)[currentCol], nchar(colnames(posteriorSample)[currentCol]), nchar(colnames(posteriorSample)[currentCol])))		predictedPrPresenceMean = predictedPrPresenceMean + mean(posteriorSample[,currentCol]) * newData[,ndColumn]^exponent				currentCol = currentCol + 1	}	predictedPrPresenceMean = inv_logit(predictedPrPresenceMean)		return(predictedPrPresenceMean)}#
inv_logit = function(x) {	inf.ind = which(x == Inf)		# negative infinity works normally, but Inf returns NaN	result = exp(x) / (1+exp(x))	result[inf.ind] = 1	return(result)}in.range = function(x, lims) x >= lims[1] & x <= lims[2]#
main()
rm(list=ls())
# 5-make_figure.r# #   Copyright 2014 Matthew V Talluto, Isabelle Boulangeat, Dominique Gravel# #   This program is free software; you can redistribute it and/or modify#   it under the terms of the GNU General Public License as published by#   the Free Software Foundation; either version 3 of the License, or (at#   your option) any later version.#   #   This program is distributed in the hope that it will be useful, but#   WITHOUT ANY WARRANTY; without even the implied warranty of#   MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU#   General Public License for more details.# #   You should have received a copy of the GNU General Public License#   along with this program; if not, write to the Free Software#   Foundation, Inc., 51 Franklin Street, Fifth Floor, Boston, MA 02110-1301, USA.##### produce the figure for the second example###
main = function(){	require(fields)	require(rgdal)	require(coda)#
	load("dat/naive_model.rdata")	intPredictions = read.csv("results/integratedStats.csv")	load("results/integratedModel.rdata")#
	predictions = process_predictions(maple, naiveModel, intPredictions, integratedModel)	ocean = readOGR(dsn="dat/ne_50m_ocean", layer="ne_50m_ocean")	lakes = readOGR(dsn="dat/ne_50m_lakes", layer="ne_50m_lakes")	mapleRange = readOGR(dsn="dat/acersacr", layer="acersacr")	# grab specific lakes	lkNames = c("Huron", "Michigan", "Superior", "Ontario", "Erie", "St. Clair")	grLakes = lakes[as.integer(sapply(lkNames, grep, lakes$name)),]	pdfFileName = "ex2.pdf"	pdfWidth = 7.5	pdfHeight = 5.25	titleCEX = 0.7#
	# which columns to loop thru for mean and errors	meanCols = c(5,11)	SECols = meanCols + 1	## pick the data to display	latLimits = c(27,65)	longLimits = c(-105, -55)	predictionsSub = subset(predictions, in.range(lat, latLimits) & in.range(long, longLimits))	mapleAllSub = subset(maple$all, in.range(lat, latLimits) & in.range(long, longLimits))	latitude = predictionsSub[,2]	longitude = predictionsSub[,1]	meanPredictions = cbind(mapleAllSub$Phenofit_HadA2, predictionsSub[,meanCols])	errorPredictions = predictionsSub[,SECols]	## plotting settings	meanZlims = c(0,1)	meanColors = colorRampPalette(c("#ffffff", "#bdc9e1", "#045a8d", "#33338d", "#cc99ff"), interpolate='spline', bias=1, space="rgb")(200)	meanTitles = c("A. Phenofit", "B. Naive SDM", "D. Integrated")	errorTitles = c("C. Naive SDM SE", "E. Integrated SE")	meanScaleTitle = "Suitability"	errorZlims = range(errorPredictions)	errorColors = colorRampPalette(c("#ffffff", "#ffffb2", "#fecc5c", "#fd8d3c", "#e31a1c"), interpolate='spline', space="rgb", bias=1.3)(200)	errorScaleTitle = "Posterior Standard Error"	#
	# produce the plot#	pdf(file=pdfFileName, width=pdfWidth,height=pdfHeight)	quartz(width=pdfWidth,height=pdfHeight)	rangeBorder = '#FF3333bb'	rangeLwd = 1.2	rangeCol = "#66666600"	plotLayout = matrix(c(		1,2,3,		6,4,5,		7,4,5),	  byrow=T, nrow=3)	layout(plotLayout, heights=c(1, 0.5, 0.5))	par(mar=c(1,1,1,1))	for(i in 1:ncol(meanPredictions)) {		quilt.plot(longitude, latitude, meanPredictions[,i], col=meanColors, zlim=meanZlims, add.legend=F, xaxt='n', yaxt='n', useRaster=T)		plot(ocean, col="white", add=T)		plot(asRange[c(1,3,47,43),], border=rangeBorder, col=rangeCol, add=T, lwd=rangeLwd)		plot(grLakes, col="white", add=T)		mtext(meanTitles[i], adj=0, cex = titleCEX)	}	for(i in 1:ncol(errorPredictions)) {		quilt.plot(longitude, latitude, errorPredictions[,i], col=errorColors, zlim=errorZlims, add.legend=F, xaxt='n', yaxt='n', useRaster=T)		plot(ocean, col="white", add=T)		plot(asRange[c(1,3,47,43),], border=rangeBorder, col=rangeCol, add=T, lwd=rangeLwd)		plot(grLakes, col="white", add=T)		mtext(errorTitles[i], adj=0, cex = titleCEX)	}	## scale bars	par(mar=c(5,1,3,1))	image(x=seq(meanZlims[1],meanZlims[2],length.out=101), z=matrix(seq(meanZlims[1], meanZlims[2],length.out=100), 		nrow=100, ncol=1), zlim=meanZlims, col=meanColors, yaxt='n', xlab='', ylab='', useRaster=T)	mtext(meanScaleTitle, line=0.5, cex = titleCEX)	image(x=seq(errorZlims[1],errorZlims[2],length.out=101), z=matrix(seq(errorZlims[1], errorZlims[2],length.out=100), 		nrow=100, ncol=1), zlim=errorZlims, col=errorColors, yaxt='n', xlab='', ylab='', useRaster=T)	mtext(errorScaleTitle, line=0.5, cex = titleCEX)#	dev.off()}#
process_predictions = function(maple, naiveModel, intPredictions, intPosterior){##	builds an object containing the predictions of all models, both for all of the#	original data points (in result$all) and for the validation points (result$valid)##	maple: the same maple object saved in step 1#	naiveModel: the glm object representing the naive model#	intPredictions: a data frame of predictions (produced in step 4)#	intPosterior: the posterior samples from the integrated model, produced by step 3#	# extract only the relevant climate variables	presClimate = maple$all[,which(colnames(maple$calib) %in% 		unique(naiveModel$variables$varNames))]	futClimate = maple$all[,which(substr(colnames(maple$calib),5, nchar(colnames(maple$calib)))		%in% unique(naiveModel$variables$varNames))]	colnames(futClimate) = colnames(presClimate)	# apply the transformations used in the calibration data to the projection datasets	presClimate = as.data.frame(sapply(names(presClimate), function(name) {		maple$transformations[[name]]$forward(presClimate[,name])}))	futClimate = as.data.frame(sapply(names(futClimate), function(name) {		maple$transformations[[name]]$forward(futClimate[,name])}))	# produce predictions for the naive model	naivePresPred = predict(naiveModel$model, newdata=presClimate, type='response', se.fit=TRUE)	naiveFutPred = predict(naiveModel$model, newdata=futClimate, type='response', se.fit=TRUE)	# wrap everything into a data frame	predictions = cbind(maple$all[,1:2], naivePresPred$fit, naivePresPred$se.fit, 		naiveFutPred$fit, naiveFutPred$se.fit, intPredictions)	colnames(predictions) = c("long", "lat", 		'naivePresent', 'naivePresentSE', 'naiveFuture', 'naiveFutureSE',		'intPresent', 'intPresentSE', 'intPresentLower', 'intPresentUpper',		'intFuture', 'intFutureSE', 'intFutureLower', 'intFutureUpper')#
	return(predictions)}#
# predict_mcmc = function(posteriorSample, newData) # {# ## #	Works like predict(), but for mcmc samples# #	Returns the average prediction for each point in the new dataset# #	# #	posteriorSample: mcmc object; the posterior sample from which to produce predictions# #	newData: data frame of predictors where predictions should be produced# ## 	parPrefix = 2# 	parEnd = 1	# 	# 	# predict the prob of presence for each point in newData# 	# assumes the FIRST parameter in posteriorSample is the intercept# 	predictedPrPresenceMean = mean(posteriorSample[,1])# # 	currentCol = 2# 	while(currentCol <= ncol(posteriorSample)) {# 		ndColumn = which(colnames(newData) == substr(colnames(posteriorSample)[currentCol], parPrefix + 1, nchar(colnames(posteriorSample)[currentCol]) - parEnd))# 		exponent = as.integer(substr(colnames(posteriorSample)[currentCol], nchar(colnames(posteriorSample)[currentCol]), nchar(colnames(posteriorSample)[currentCol])))# 		predictedPrPresenceMean = predictedPrPresenceMean + mean(posteriorSample[,currentCol]) * newData[,ndColumn]^exponent		# 		currentCol = currentCol + 1# 	}# 	predictedPrPresenceMean = inv_logit(predictedPrPresenceMean)	# 	return(predictedPrPresenceMean)# }# # # inv_logit = function(x) {# 	inf.ind = which(x == Inf)		# negative infinity works normally, but Inf returns NaN# 	result = exp(x) / (1+exp(x))# 	result[inf.ind] = 1# 	return(result)# }in.range = function(x, lims) x >= lims[1] & x <= lims[2]#
main()
rm(list=ls())
# 5-make_figure.r# #   Copyright 2014 Matthew V Talluto, Isabelle Boulangeat, Dominique Gravel# #   This program is free software; you can redistribute it and/or modify#   it under the terms of the GNU General Public License as published by#   the Free Software Foundation; either version 3 of the License, or (at#   your option) any later version.#   #   This program is distributed in the hope that it will be useful, but#   WITHOUT ANY WARRANTY; without even the implied warranty of#   MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU#   General Public License for more details.# #   You should have received a copy of the GNU General Public License#   along with this program; if not, write to the Free Software#   Foundation, Inc., 51 Franklin Street, Fifth Floor, Boston, MA 02110-1301, USA.##### produce the figure for the second example###
main = function(){	require(fields)	require(rgdal)	require(coda)#
	load("dat/naive_model.rdata")	intPredictions = read.csv("results/integratedStats.csv")	load("results/integratedModel.rdata")#
	predictions = process_predictions(maple, naiveModel, intPredictions, integratedModel)	ocean = readOGR(dsn="dat/ne_50m_ocean", layer="ne_50m_ocean")	lakes = readOGR(dsn="dat/ne_50m_lakes", layer="ne_50m_lakes")	mapleRange = readOGR(dsn="dat/acersacr", layer="acersacr")	# grab specific lakes	lkNames = c("Huron", "Michigan", "Superior", "Ontario", "Erie", "St. Clair")	grLakes = lakes[as.integer(sapply(lkNames, grep, lakes$name)),]	pdfFileName = "ex2.pdf"	pdfWidth = 7.5	pdfHeight = 5.25	titleCEX = 0.7#
	# which columns to loop thru for mean and errors	meanCols = c(5,11)	SECols = meanCols + 1	## pick the data to display	latLimits = c(27,65)	longLimits = c(-105, -55)	predictionsSub = subset(predictions, in.range(lat, latLimits) & in.range(long, longLimits))	mapleAllSub = subset(maple$all, in.range(lat, latLimits) & in.range(long, longLimits))	latitude = predictionsSub[,2]	longitude = predictionsSub[,1]	meanPredictions = cbind(mapleAllSub$Phenofit_HadA2, predictionsSub[,meanCols])	errorPredictions = predictionsSub[,SECols]	## plotting settings	meanZlims = c(0,1)	meanColors = colorRampPalette(c("#ffffff", "#bdc9e1", "#045a8d", "#33338d", "#cc99ff"), interpolate='spline', bias=1, space="rgb")(200)	meanTitles = c("A. Phenofit", "B. Naive SDM", "D. Integrated")	errorTitles = c("C. Naive SDM SE", "E. Integrated SE")	meanScaleTitle = "Suitability"	errorZlims = range(errorPredictions)	errorColors = colorRampPalette(c("#ffffff", "#ffffb2", "#fecc5c", "#fd8d3c", "#e31a1c"), interpolate='spline', space="rgb", bias=1.3)(200)	errorScaleTitle = "Posterior Standard Error"	#
	# produce the plot#	pdf(file=pdfFileName, width=pdfWidth,height=pdfHeight)	quartz(width=pdfWidth,height=pdfHeight)	rangeBorder = '#FF3333bb'	rangeLwd = 1.2	rangeCol = "#66666600"	plotLayout = matrix(c(		1,2,3,		6,4,5,		7,4,5),	  byrow=T, nrow=3)	layout(plotLayout, heights=c(1, 0.5, 0.5))	par(mar=c(1,1,1,1))	for(i in 1:ncol(meanPredictions)) {		quilt.plot(longitude, latitude, meanPredictions[,i], col=meanColors, zlim=meanZlims, add.legend=F, xaxt='n', yaxt='n', useRaster=T)		plot(ocean, col="white", add=T)		plot(mapleRange[c(1,3,47,43),], border=rangeBorder, col=rangeCol, add=T, lwd=rangeLwd)		plot(grLakes, col="white", add=T)		mtext(meanTitles[i], adj=0, cex = titleCEX)	}	for(i in 1:ncol(errorPredictions)) {		quilt.plot(longitude, latitude, errorPredictions[,i], col=errorColors, zlim=errorZlims, add.legend=F, xaxt='n', yaxt='n', useRaster=T)		plot(ocean, col="white", add=T)		plot(mapleRange[c(1,3,47,43),], border=rangeBorder, col=rangeCol, add=T, lwd=rangeLwd)		plot(grLakes, col="white", add=T)		mtext(errorTitles[i], adj=0, cex = titleCEX)	}	## scale bars	par(mar=c(5,1,3,1))	image(x=seq(meanZlims[1],meanZlims[2],length.out=101), z=matrix(seq(meanZlims[1], meanZlims[2],length.out=100), 		nrow=100, ncol=1), zlim=meanZlims, col=meanColors, yaxt='n', xlab='', ylab='', useRaster=T)	mtext(meanScaleTitle, line=0.5, cex = titleCEX)	image(x=seq(errorZlims[1],errorZlims[2],length.out=101), z=matrix(seq(errorZlims[1], errorZlims[2],length.out=100), 		nrow=100, ncol=1), zlim=errorZlims, col=errorColors, yaxt='n', xlab='', ylab='', useRaster=T)	mtext(errorScaleTitle, line=0.5, cex = titleCEX)#	dev.off()}#
process_predictions = function(maple, naiveModel, intPredictions, intPosterior){##	builds an object containing the predictions of all models, both for all of the#	original data points (in result$all) and for the validation points (result$valid)##	maple: the same maple object saved in step 1#	naiveModel: the glm object representing the naive model#	intPredictions: a data frame of predictions (produced in step 4)#	intPosterior: the posterior samples from the integrated model, produced by step 3#	# extract only the relevant climate variables	presClimate = maple$all[,which(colnames(maple$calib) %in% 		unique(naiveModel$variables$varNames))]	futClimate = maple$all[,which(substr(colnames(maple$calib),5, nchar(colnames(maple$calib)))		%in% unique(naiveModel$variables$varNames))]	colnames(futClimate) = colnames(presClimate)	# apply the transformations used in the calibration data to the projection datasets	presClimate = as.data.frame(sapply(names(presClimate), function(name) {		maple$transformations[[name]]$forward(presClimate[,name])}))	futClimate = as.data.frame(sapply(names(futClimate), function(name) {		maple$transformations[[name]]$forward(futClimate[,name])}))	# produce predictions for the naive model	naivePresPred = predict(naiveModel$model, newdata=presClimate, type='response', se.fit=TRUE)	naiveFutPred = predict(naiveModel$model, newdata=futClimate, type='response', se.fit=TRUE)	# wrap everything into a data frame	predictions = cbind(maple$all[,1:2], naivePresPred$fit, naivePresPred$se.fit, 		naiveFutPred$fit, naiveFutPred$se.fit, intPredictions)	colnames(predictions) = c("long", "lat", 		'naivePresent', 'naivePresentSE', 'naiveFuture', 'naiveFutureSE',		'intPresent', 'intPresentSE', 'intPresentLower', 'intPresentUpper',		'intFuture', 'intFutureSE', 'intFutureLower', 'intFutureUpper')#
	return(predictions)}#
# predict_mcmc = function(posteriorSample, newData) # {# ## #	Works like predict(), but for mcmc samples# #	Returns the average prediction for each point in the new dataset# #	# #	posteriorSample: mcmc object; the posterior sample from which to produce predictions# #	newData: data frame of predictors where predictions should be produced# ## 	parPrefix = 2# 	parEnd = 1	# 	# 	# predict the prob of presence for each point in newData# 	# assumes the FIRST parameter in posteriorSample is the intercept# 	predictedPrPresenceMean = mean(posteriorSample[,1])# # 	currentCol = 2# 	while(currentCol <= ncol(posteriorSample)) {# 		ndColumn = which(colnames(newData) == substr(colnames(posteriorSample)[currentCol], parPrefix + 1, nchar(colnames(posteriorSample)[currentCol]) - parEnd))# 		exponent = as.integer(substr(colnames(posteriorSample)[currentCol], nchar(colnames(posteriorSample)[currentCol]), nchar(colnames(posteriorSample)[currentCol])))# 		predictedPrPresenceMean = predictedPrPresenceMean + mean(posteriorSample[,currentCol]) * newData[,ndColumn]^exponent		# 		currentCol = currentCol + 1# 	}# 	predictedPrPresenceMean = inv_logit(predictedPrPresenceMean)	# 	return(predictedPrPresenceMean)# }# # # inv_logit = function(x) {# 	inf.ind = which(x == Inf)		# negative infinity works normally, but Inf returns NaN# 	result = exp(x) / (1+exp(x))# 	result[inf.ind] = 1# 	return(result)# }in.range = function(x, lims) x >= lims[1] & x <= lims[2]#
main()
